{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlqynMqsdCc3"
      },
      "source": [
        "# AI DDE Hackathon\n",
        "\n",
        "Update the cell below with your Huggingface token (see: https://huggingface.co/docs/hub/en/security-tokens) and ensure you have permssion to use the LLama 3 Model (https://huggingface.co/meta-llama/Llama-3.1-8B)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jO5aVH1HDKt9",
        "outputId": "37e72700-36ce-4778-d765-bf31e91b43c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting markitdown\n",
            "  Downloading markitdown-0.0.1a3-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.14)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.12.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.7.5)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from markitdown) (4.12.3)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from markitdown) (3.4.1)\n",
            "Collecting mammoth (from markitdown)\n",
            "  Downloading mammoth-1.9.0-py2.py3-none-any.whl.metadata (24 kB)\n",
            "Collecting markdownify (from markitdown)\n",
            "  Downloading markdownify-0.14.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from markitdown) (1.26.4)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (from markitdown) (1.59.6)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (from markitdown) (3.1.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from markitdown) (2.2.2)\n",
            "Collecting pathvalidate (from markitdown)\n",
            "  Downloading pathvalidate-3.2.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pdfminer-six (from markitdown)\n",
            "  Downloading pdfminer.six-20240706-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting puremagic (from markitdown)\n",
            "  Downloading puremagic-1.28-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting pydub (from markitdown)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-pptx (from markitdown)\n",
            "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from markitdown) (2.32.3)\n",
            "Collecting speechrecognition (from markitdown)\n",
            "  Downloading SpeechRecognition-3.14.0-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting youtube-transcript-api (from markitdown)\n",
            "  Downloading youtube_transcript_api-0.6.3-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.11)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.29)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.2.10)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.5)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.9.2-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.29.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.29.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.0)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.69.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.1)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.0.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.14)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.5.4 (from gradio)\n",
            "  Downloading gradio_client-1.5.4-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.27.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.9.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.45.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.5.4->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.5.4->gradio) (14.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (1.33)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.12.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (4.25.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.15)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.29.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-instrumentation==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
            "Collecting opentelemetry-util-http==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.50b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.0)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->markitdown) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->markitdown) (2024.2)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->markitdown) (2.6)\n",
            "Collecting cobble<0.2,>=0.1.3 (from mammoth->markitdown)\n",
            "  Downloading cobble-0.1.4-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai->markitdown) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai->markitdown) (0.8.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl->markitdown) (2.0.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer-six->markitdown) (43.0.3)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx->markitdown)\n",
            "  Downloading XlsxWriter-3.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx->markitdown) (5.3.0)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api->markitdown) (0.7.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer-six->markitdown) (1.17.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain) (3.0.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer-six->markitdown) (2.22)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading markitdown-0.0.1a3-py3-none-any.whl (16 kB)\n",
            "Downloading chromadb-0.6.3-py3-none-any.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-5.12.0-py3-none-any.whl (57.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.5.4-py3-none-any.whl (321 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.4/321.4 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading mmh3-5.0.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.29.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_util_http-0.50b0-py3-none-any.whl (6.9 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.9.2-py2.py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.8/70.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.9.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m109.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading mammoth-1.9.0-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.9/52.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdownify-0.14.1-py3-none-any.whl (11 kB)\n",
            "Downloading pathvalidate-3.2.3-py3-none-any.whl (24 kB)\n",
            "Downloading pdfminer.six-20240706-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m113.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading puremagic-1.28-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading SpeechRecognition-3.14.0-py3-none-any.whl (32.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading youtube_transcript_api-0.6.3-py3-none-any.whl (622 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.3/622.3 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading cobble-0.1.4-py3-none-any.whl (4.0 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53771 sha256=5dff8328cf335be8f91fa75834fbe40d08077393c4f65dcfd92025bf21c19e51\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, pydub, puremagic, monotonic, durationpy, XlsxWriter, uvloop, uvicorn, tomlkit, speechrecognition, semantic-version, ruff, python-multipart, python-dotenv, pyproject_hooks, protobuf, pathvalidate, overrides, opentelemetry-util-http, mmh3, markupsafe, humanfriendly, httptools, ffmpy, cobble, chroma-hnswlib, bcrypt, backoff, asgiref, aiofiles, youtube-transcript-api, watchfiles, starlette, python-pptx, posthog, opentelemetry-proto, markdownify, mammoth, coloredlogs, build, safehttpx, pdfminer-six, opentelemetry-exporter-otlp-proto-common, onnxruntime, kubernetes, gradio-client, fastapi, opentelemetry-instrumentation, markitdown, gradio, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed XlsxWriter-3.2.0 aiofiles-23.2.1 asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.1 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.6.3 cobble-0.1.4 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.6 ffmpy-0.5.0 gradio-5.12.0 gradio-client-1.5.4 httptools-0.6.4 humanfriendly-10.0 kubernetes-31.0.0 mammoth-1.9.0 markdownify-0.14.1 markitdown-0.0.1a3 markupsafe-2.1.5 mmh3-5.0.1 monotonic-1.6 onnxruntime-1.20.1 opentelemetry-exporter-otlp-proto-common-1.29.0 opentelemetry-exporter-otlp-proto-grpc-1.29.0 opentelemetry-instrumentation-0.50b0 opentelemetry-instrumentation-asgi-0.50b0 opentelemetry-instrumentation-fastapi-0.50b0 opentelemetry-proto-1.29.0 opentelemetry-util-http-0.50b0 overrides-7.7.0 pathvalidate-3.2.3 pdfminer-six-20240706 posthog-3.9.2 protobuf-5.29.3 puremagic-1.28 pydub-0.25.1 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.0.1 python-multipart-0.0.20 python-pptx-1.0.2 ruff-0.9.2 safehttpx-0.1.6 semantic-version-2.10.0 speechrecognition-3.14.0 starlette-0.41.3 tomlkit-0.13.2 uvicorn-0.34.0 uvloop-0.21.0 watchfiles-1.0.4 youtube-transcript-api-0.6.3\n",
            "Collecting git+https://github.com/huggingface/transformers.git\n",
            "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-tv1k33vu\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-tv1k33vu\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit 2c3a44f9a769e98597d62ecdc7383785318be5a2\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting flash-attn\n",
            "  Downloading flash_attn-2.7.3.tar.gz (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash-attn) (2.5.1+cu121)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash-attn) (0.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.49.0.dev0) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.49.0.dev0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.49.0.dev0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.49.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.49.0.dev0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.49.0.dev0) (2024.12.14)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash-attn) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->flash-attn) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash-attn) (2.1.5)\n",
            "Building wheels for collected packages: flash-attn, transformers\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.7.3-cp311-cp311-linux_x86_64.whl size=191363917 sha256=b1243e9b86687348a5ab03a073abacdf8e3d5e9e4b7e5326a183f47348c5dfba\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/a3/f9/48d2706cb2eac05ec0dc144bf6954fe47bb3c2cd0de280765e\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.49.0.dev0-py3-none-any.whl size=10489405 sha256=cabac727faeca8e31f4a1292b24cc029c5aacb97620ce79fa9e37535cba4c025\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8fdeli0j/wheels/32/4b/78/f195c684dd3a9ed21f3b39fe8f85b48df7918581b6437be143\n",
            "Successfully built flash-attn transformers\n",
            "Installing collected packages: transformers, flash-attn\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.47.1\n",
            "    Uninstalling transformers-4.47.1:\n",
            "      Successfully uninstalled transformers-4.47.1\n",
            "Successfully installed flash-attn-2.7.3 transformers-4.49.0.dev0\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.5-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pymupdf\n",
            "  Downloading pymupdf-1.25.2-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting pdfminer.six==20231228 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.1.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m20.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Downloading pdfplumber-0.11.5-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m113.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymupdf-1.25.2-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pymupdf, pdfminer.six, pdfplumber\n",
            "  Attempting uninstall: pdfminer.six\n",
            "    Found existing installation: pdfminer.six 20240706\n",
            "    Uninstalling pdfminer.six-20240706:\n",
            "      Successfully uninstalled pdfminer.six-20240706\n",
            "Successfully installed pdfminer.six-20231228 pdfplumber-0.11.5 pymupdf-1.25.2 pypdfium2-4.30.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<frozen importlib._bootstrap>:1047: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install markitdown langchain chromadb gradio spacy\n",
        "!pip install flash-attn git+https://github.com/huggingface/transformers.git triton\n",
        "\n",
        "\n",
        "! pip install pdfplumber pymupdf\n",
        "# Import basic libraries\n",
        "import os\n",
        "from markitdown import MarkItDown\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import torch\n",
        "import logging\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "from google.colab import userdata\n",
        "\n",
        "HF_TOKEN = userdata.get('HUGGING_FACE_HUB_TOKEN')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eveovtxD5QRm",
        "outputId": "0f729c55-9988-4cf1-f4d9-a2a797879670",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "# Create documents folder\n",
        "DOCUMENTS_PATH = '/content/drive/MyDrive/legal_documents'\n",
        "if not os.path.exists(DOCUMENTS_PATH):\n",
        "    os.makedirs(DOCUMENTS_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAAi0qC3D_dR"
      },
      "source": [
        "Document Processor Class\n",
        "\n",
        "This cell defines our core document processing system:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAvH6rSuG6Zv"
      },
      "outputs": [],
      "source": [
        "import pdfplumber\n",
        "import re\n",
        "import fitz  # PyMuPDF\n",
        "\n",
        "class PDFProccessor:\n",
        "\n",
        "  pdf_path = None\n",
        "\n",
        "  def __init__(self, pdf_path):\n",
        "    self.pdf_path = pdf_path\n",
        "    pass\n",
        "\n",
        "  def process_pdf(self):\n",
        "    text = self.open_pdf()\n",
        "    print(self.remove_page_numbers(text))\n",
        "\n",
        "  def open_pdf(self):\n",
        "    with pdfplumber.open(self.pdf_path) as pdf:\n",
        "        text = \"\"\n",
        "        for page in pdf.pages:\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "    return text\n",
        "\n",
        "  def remove_page_numbers(self, text):\n",
        "    extrapolations_pattern =  r\"^\\s*THE\\s+EXTRAPOLATIONS\\s+DOCUMENT(?:\\s*\\n\\s*|\\s+)*\\d+\\s*$\"\n",
        "    dangling_page_number = r\"^\\s*\\d+\\s*$\"\n",
        "    clean_text = re.sub(extrapolations_pattern, \"\", text, flags=re.MULTILINE)\n",
        "    return re.sub(dangling_page_number, \"\", clean_text, flags=re.MULTILINE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pPRn0pmzNm_"
      },
      "source": [
        "This I think might help reduce the tokens for RAG."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = \"/content/drive/MyDrive/legal_documents/Leiden Guidelines on the Use of DDE in ICCTs_20220404.pdf\"\n",
        "\n",
        "def extract_sections_with_headers(pdf_path):\n",
        "    pages = []\n",
        "\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            pages.append( page.extract_text())\n",
        "    return pages\n",
        "\n",
        "pages = extract_sections_with_headers(pdf_path)\n",
        "for page in pages:\n",
        "    print(f\"Text: {page[:200]}...\")  # Display first 200 chars of text\n",
        "    print(\"---\")"
      ],
      "metadata": {
        "id": "IaiqMMRZpobo",
        "outputId": "db54267a-3e0f-45f7-bf06-7b87810bc5b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: Leiden Guidelines\n",
            "on the Use of Digitally Derived Evidence\n",
            "in International Criminal Courts and Tribunals\n",
            "Sofia Aalto-Setälä Supervisor\n",
            "Luca Caroli Sabrina K. Rewald, J.D., LL.M.\n",
            "Julia Freytag\n",
            "Maria F...\n",
            "---\n",
            "Text: Table of Contents\n",
            "I. INTRODUCTION ......................................................................................................................................... 3\n",
            "A. DEFINITION OF DDE ........\n",
            "---\n",
            "Text: D.2. The probative value of intercepts may be enhanced by tendering the original audio\n",
            "recordings. ........................................................................................................\n",
            "---\n",
            "Text: I. Introduction\n",
            "Digitally Derived Evidence (DDE) is increasingly used in international criminal courts and\n",
            "tribunals to prosecute perpetrators of international crimes. Advanced digital tools, includin...\n",
            "---\n",
            "Text: a “computer environment,” as well as ‘digitized evidence,’ which is analogue material that has\n",
            "been transferred to a digital format.2 The concept is rooted in the following definitions:\n",
            "International ...\n",
            "---\n",
            "Text: practitioners with a detailed level of analysis from which they will have the flexibility to expand\n",
            "on points of interest and relevant information further. The authors hope these materials will\n",
            "help l...\n",
            "---\n",
            "Text: Protocol, which provides the technical standards by which digital evidence should be prepared\n",
            "and provided to the Court.6\n",
            "The Leiden Guidelines draw upon the ICC’s approach to evidence, as set out by ...\n",
            "---\n",
            "Text: Probative Value. Often used interchangeably with the concept of weight, evidence is\n",
            "probative if it tends to prove or disprove an asserted fact. In other words, evidence that is\n",
            "probative has the qual...\n",
            "---\n",
            "Text: of the proceedings (Article 69(7) of the Rome Statute).20 Certain types of DDE, for example,\n",
            "raise particular concerns about the human right to privacy, as will be discussed in greater detail\n",
            "within t...\n",
            "---\n",
            "Text: evidence of witness interference,26 and the Defence in Taylor presented an email as an item of\n",
            "additional evidence to substantiate the grounds of appeal before the SCSL.27 However, in both\n",
            "cases, the ...\n",
            "---\n",
            "Text: II. The Leiden Guidelines\n",
            "A. Videos\n",
            "Definition\n",
            "The international courts and tribunals do not define the concept of videos. However, in general\n",
            "terms, video recordings are commonly referred to as ‘audi...\n",
            "---\n",
            "Text: granted the Prosecution’s request to admit extensions of video excerpts that had been\n",
            "tendered by the Defence in order to illustrate the reason behind the presence of community\n",
            "leaders at an event dep...\n",
            "---\n",
            "Text: necessary if the purpose of the video is to demonstrate ambient sound;41 the Defence in Mladić\n",
            "at the ICTY was not required to transcribe the ambient sound of a firefight in a video it\n",
            "tendered.42\n",
            "A.3...\n",
            "---\n",
            "Text: the Trial Chamber ultimately found that the video did not bear ‘sufficient probative value for\n",
            "admission’.49\n",
            "Translation by Counsel. Videos adduced from other sources and devoid of translation\n",
            "and tra...\n",
            "---\n",
            "Text: A.4. When a witness appears on a video that the party intends to tender\n",
            "into evidence, the video should be tendered through the witness during the\n",
            "examination-in-chief and not through the bar table.\n",
            "K...\n",
            "---\n",
            "Text: in Karemera et al admitted videos which depicted violence and killings in Rwanda, but\n",
            "disregarded any accompanying comments made by journalists in the videos.61\n",
            "Nevertheless, caution should be exercis...\n",
            "---\n",
            "Text: A.6. Videos can be admitted into evidence if relevance and prima facie\n",
            "authenticity is demonstrated by providing information about the date, the\n",
            "location, the events depicted, the author, the source, ...\n",
            "---\n",
            "Text: Chamber in Ntaganda declined to admit a video where the Prosecution was only able to provide\n",
            "the date the video had been broadcast, but not the date the video had been shot.76\n",
            "Open Source Videos of Me...\n",
            "---\n",
            "Text: A.7. Video evidence of interviews conducted during an armed conflict by a\n",
            "party to the conflict may not be objective and reliable and therefore low\n",
            "probative value may be attached to the video.\n",
            "Keywor...\n",
            "---\n",
            "Text: only be used when no acceptable alternative investigative approach is available.89 Once\n",
            "evidence has been disclosed pursuant to Article 67(2) of the Rome Statute or Rules 76 or 77\n",
            "of the ICC Rules of ...\n",
            "---\n",
            "Text: B. Photographs\n",
            "Definition\n",
            "Photographs are widely used within international criminal proceedings, but despite their\n",
            "common usage, courts and tribunals have not undertaken to provide a widespread defini...\n",
            "---\n",
            "Text: B.2. Photographs can be admitted into evidence if prima facie authenticity\n",
            "is demonstrated by providing information about the date, the location, the\n",
            "events depicted, the author, the source, and/or th...\n",
            "---\n",
            "Text: Trial Chamber in Bemba also discussed this when considering two photographs, stating that\n",
            "since the Prosecution had not provided ‘any information or evidence to support their\n",
            "authenticity and reliabil...\n",
            "---\n",
            "Text: caused by the angle of photography.108 Exposure to such software undermined the reliability\n",
            "of photographs as they were no longer submitted in their original form.\n",
            "B.4. The consent of witnesses and ot...\n",
            "---\n",
            "Text: C. Aerial and Satellite Images\n",
            "Definition\n",
            "Although Courts and Tribunals do not provide a standardised definition of this type of DDE,\n",
            "the term ‘satellite images’ has been used to describe digitally tr...\n",
            "---\n",
            "Text: C.2. Aerial and satellite images admitted during former witness testimony\n",
            "are admissible if they form an inseparable and indispensable part of that\n",
            "testimony.\n",
            "Keywords: procedure; former testimony; ex...\n",
            "---\n",
            "Text: the expert was a live witness whose report is highly relevant to the case and admissible under\n",
            "Rule 89 and its Guidelines on the Standards Governing the Admission of Evidence, and who\n",
            "the Defence woul...\n",
            "---\n",
            "Text: C.4. Aerial and satellite images can be used to corroborate other evidence.\n",
            "Keywords: relevance; corroboration\n",
            "Aerial and satellite images can be used to corroborate other evidence such as forensic\n",
            "ev...\n",
            "---\n",
            "Text: credibility is safeguarded if accompanied by expert reports locating the places/individuals\n",
            "depicted.140\n",
            "Errors. The overall weight of aerial and satellite images is not adversely affected by\n",
            "technica...\n",
            "---\n",
            "Text: D. Intercepts\n",
            "Definition\n",
            "Intercepts fall under documentary evidence and can be characterised as ‘anything in which\n",
            "information of any description is recorded.’147 Intercepts are audio communications\n",
            "i...\n",
            "---\n",
            "Text: found that counsel could file a bar table motion for its intercept operator evidence in advance\n",
            "of calling witnesses for that section of its case, and by doing so reducing the number of\n",
            "witnesses that...\n",
            "---\n",
            "Text: probative value of the intercepts, such that it was not substantially outweighed by the need to\n",
            "ensure a fair trial.158\n",
            "Original Intercepted Audio Recordings. It is not necessary for the Court to have...\n",
            "---\n",
            "Text: in Tolimir held, concerning intercepted radio communications, that independent corroboration\n",
            "and overwhelming weight of other evidence served to establish the intercepts’ reliability and\n",
            "authenticity ...\n",
            "---\n",
            "Text: the Trial Chamber may nevertheless take a comprehensive approach and admit them: in Mladić,\n",
            "it found that the intercepts related to the Srebrenica section of the Prosecution’s case, some\n",
            "of which were...\n",
            "---\n",
            "Text: D.4. Relevance of intercepts, which are not in a working language of the\n",
            "Court, may not be assessed when there is no relevant and accurate translation.\n",
            "Not all mistakes in translations or transcripts ...\n",
            "---\n",
            "Text: The argument regarding interpretation goes to the weight, not admissibility (which is to be\n",
            "assessed at a later stage) in light of the totality of the evidence.185\n",
            "Mistakes in Translations and Transcr...\n",
            "---\n",
            "Text: grade and amateur grade manufactured devices: military devices are always more sensitive,\n",
            "and need to meet other challenges, like the configuration of the land, weather, and/or the way\n",
            "in which they a...\n",
            "---\n",
            "Text: evaluation of the evidence concerning specific topics, names and locations.198 The ICC noted\n",
            "that the reliability of the recording depends on the type of information the Chamber is relying\n",
            "on, and tha...\n",
            "---\n",
            "Text: D.8. The collection of intercepted communication evidence will not\n",
            "constitute a violation of privacy if it is provided for by law, necessary, and\n",
            "proportionate.\n",
            "Keywords: prejudice; privacy\n",
            "Pursuant t...\n",
            "---\n",
            "Text: talkie and simultaneously recorded by a journalist on a small Sony tape)208 recorded ‘by\n",
            "eavesdropping on an enemy’s telephone calls during the course of a war’ was ‘certainly not\n",
            "within the conduct w...\n",
            "---\n",
            "Text: the integrity of the proceedings, will determine their admissibility.217 The ICTY Trial Chamber,\n",
            "moreover, found that its jurisprudence had never endorsed the exclusionary rule as a matter\n",
            "of principl...\n",
            "---\n",
            "Text: of communications protected by privilege as envisaged in the Court’s legal framework would\n",
            "not be accessed by the Prosecution.’224\n",
            "224 Prosecutor v Bemba et al (Judgment on the appeals of Mr Jean-Pier...\n",
            "---\n",
            "Text: E. Call Data Records\n",
            "Definition\n",
            "Call Data Records (CDRs) are defined as metadata that do not contain the content of any\n",
            "communications, but solely provide information about them, such as the source an...\n",
            "---\n",
            "Text: Instead, the CDRs should be rendered intelligible through Call Sequence Tables (CSTs).\n",
            "The STL Prosecution in Ayyash et al produced a CST presenting a chronological sequence of\n",
            "calls relating to a tar...\n",
            "---\n",
            "Text: Disclosure of Related Documents. Pursuant to Rule 71(B) of the IRMCT Rules of\n",
            "Procedure and Evidence, the Prosecutor shall permit the Defence to inspect any books,\n",
            "documents, photographs, and tangible...\n",
            "---\n",
            "Text: communications evidence. The ICC Trial Chamber in Bemba et al found that call data reinforced\n",
            "and confirmed the accuracy of the intercepted communications as they were consistent with\n",
            "each other.243 C...\n",
            "---\n",
            "Text: their content is of no practical utility in its raw form.249 Instead, the tendering party should\n",
            "provide contextual evidence on its chain of custody, including evidence on the creation,\n",
            "storage, and r...\n",
            "---\n",
            "Text: telecommunications provider or self-identification at the start of intercepted calls;258\n",
            "intercepted communications which matched the corresponding call data;259 expert testimony\n",
            "on the origins of the...\n",
            "---\n",
            "Text: second, the national authority’s subsequent authorisation to carry out the requested\n",
            "collection.264 The former is based on the Prosecutor’s powers with respect to investigations\n",
            "under Article 54(3) of...\n",
            "---\n",
            "Text: Call Sequence Tables (CSTs) with which to construct the case and file the indictments against\n",
            "the accused.270\n",
            "Proportionality. The proportionality of the collection of the CDRs is assessed with\n",
            "refere...\n",
            "---\n",
            "Text: F. Audio Recordings\n",
            "Definition\n",
            "Audio recordings are recordings ‘made on any disc, tape or other device on which sounds are\n",
            "recorded so as to be capable of being reproduced’.274 For the purposes of the...\n",
            "---\n",
            "Text: F.2. Audio recordings of media broadcasts are relevant if they refer to\n",
            "events that took place during the time period relevant to the charges and are\n",
            "contemporaneous with the events.\n",
            "Keywords: relevan...\n",
            "---\n",
            "Text: CAR-OTP-0031-0099 (a Radio France Internationale programme concerning the situation in\n",
            "the Central African Republic dated 5 December 2002) could ‘serve to corroborate other pieces\n",
            "of evidence and migh...\n",
            "---\n",
            "Text: Open Source Audio Recordings of Media Broadcasts. The ICC Trial Chamber in Bemba\n",
            "held that where the audio recording of an interview lacks a date and contains no questions, the\n",
            "tendering party must pr...\n",
            "---\n",
            "Text: F.5. Insufficient authentication goes to the weight of audio recordings\n",
            "rather than their admissibility.\n",
            "Keywords: relevance; probative value; hearsay; admissibility\n",
            "Pursuant to Rule 92 bis of the SCS...\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_pages(pages_array):\n",
        "    filtered_pages = []\n",
        "    start_processing = False\n",
        "\n",
        "    for page_number, text in enumerate(pages_array):\n",
        "        # Skip the cover page (assumed to be the first page)\n",
        "        if page_number == 0:\n",
        "            continue\n",
        "\n",
        "        # Skip the Table of Contents\n",
        "        if \"Table of Contents\" in text:\n",
        "            continue\n",
        "\n",
        "        # Start processing after \"I. Introduction\"\n",
        "        if not start_processing and \"I. Introduction\" in text:\n",
        "            start_processing = True\n",
        "            # Process content after \"I. Introduction\" within the page\n",
        "            text = text.split(\"I. Introduction\", 1)[1]\n",
        "\n",
        "        if start_processing:\n",
        "            filtered_pages.append(text.strip())\n",
        "\n",
        "    return filtered_pages\n",
        "\n",
        "filtered_pages = filter_pages(pages)\n",
        "\n",
        "# Output the filtered pages to verify\n",
        "for i, page in enumerate(filtered_pages):\n",
        "    print(f\"Filtered Page {i + 1}:\")\n",
        "    print(page[:500])  # Print the first 500 characters of the page\n",
        "    print(\"---\")"
      ],
      "metadata": {
        "id": "qpeT3Ikjy3_5",
        "outputId": "b4229b20-feff-4d0e-cef9-653b97c6a535",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered Page 1:\n",
            "Digitally Derived Evidence (DDE) is increasingly used in international criminal courts and\n",
            "tribunals to prosecute perpetrators of international crimes. Advanced digital tools, including\n",
            "aerial photography, mobile devices, video, intercepted communications, amongst others,\n",
            "capture new and vast quantities of data, which can add supplementary and supporting data to\n",
            "existing evidence. For example, while an eyewitness account may provide relevant information\n",
            "regarding an event, a satellite image may \n",
            "---\n",
            "Filtered Page 2:\n",
            "a “computer environment,” as well as ‘digitized evidence,’ which is analogue material that has\n",
            "been transferred to a digital format.2 The concept is rooted in the following definitions:\n",
            "International Bar Association (IBA)\n",
            "‘Digital and technologically derived evidence, which means evidence taken from and\n",
            "created by digital devices and via technology, such as cameras, satellites and other\n",
            "‘remote sensing technologies’ […] We distinguish digital evidence, created by digital\n",
            "technology and itself th\n",
            "---\n",
            "Filtered Page 3:\n",
            "practitioners with a detailed level of analysis from which they will have the flexibility to expand\n",
            "on points of interest and relevant information further. The authors hope these materials will\n",
            "help legal practitioners navigate the evidentiary application of DDE through what is a vast\n",
            "quantity of case law and material.\n",
            "The focus of the Leiden Guidelines is on the International Criminal Court (ICC)’s practice\n",
            "and guidance, recognising the ICC’s position as the permanent international criminal jud\n",
            "---\n",
            "Filtered Page 4:\n",
            "Protocol, which provides the technical standards by which digital evidence should be prepared\n",
            "and provided to the Court.6\n",
            "The Leiden Guidelines draw upon the ICC’s approach to evidence, as set out by the ICC Trial\n",
            "Chamber in Bemba:\n",
            "‘[F]or an item to be admitted into evidence it must satisfy the three-part test under\n",
            "which it must (i) be relevant to the case; (ii) have probative value; and (iii) be sufficiently\n",
            "relevant and probative as to outweigh any prejudicial effect its admission may cause.\n",
            "\n",
            "---\n",
            "Filtered Page 5:\n",
            "Probative Value. Often used interchangeably with the concept of weight, evidence is\n",
            "probative if it tends to prove or disprove an asserted fact. In other words, evidence that is\n",
            "probative has the quality or function of demonstrating the existence of a fact.12 To be\n",
            "considered probative, evidence must reach a certain threshold. Usually at the admissibility\n",
            "stage, the tendering party only needs to show that the evidence has prima facie probative\n",
            "value.13 An assessment of probative value is based o\n",
            "---\n",
            "Filtered Page 6:\n",
            "of the proceedings (Article 69(7) of the Rome Statute).20 Certain types of DDE, for example,\n",
            "raise particular concerns about the human right to privacy, as will be discussed in greater detail\n",
            "within the Guidelines.\n",
            "D. Scope of the Leiden Guidelines\n",
            "The rules and practice surrounding the use of DDE in international criminal courts and tribunals\n",
            "continue to develop. Digital technology is being used more widely and frequently, not only in\n",
            "the investigation and prosecution of international crimes, b\n",
            "---\n",
            "Filtered Page 7:\n",
            "evidence of witness interference,26 and the Defence in Taylor presented an email as an item of\n",
            "additional evidence to substantiate the grounds of appeal before the SCSL.27 However, in both\n",
            "cases, the emails were tendered together with other types of evidence. Any discussion of\n",
            "evidentiary issues was not specific to emails, and as such no guidelines could reasonably be\n",
            "deduced or formulated.\n",
            "There was, nevertheless, sufficient guidance from the international criminal courts and\n",
            "tribunals to formu\n",
            "---\n",
            "Filtered Page 8:\n",
            "II. The Leiden Guidelines\n",
            "A. Videos\n",
            "Definition\n",
            "The international courts and tribunals do not define the concept of videos. However, in general\n",
            "terms, video recordings are commonly referred to as ‘audio-visual material’28 and as such,\n",
            "videos can be defined as ‘visual multimedia source[s] through which a series of images forms a\n",
            "moving picture. The video transmits a signal to a screen and processes the order in which the\n",
            "screen captures should be shown. Videos usually have audio components that co\n",
            "---\n",
            "Filtered Page 9:\n",
            "granted the Prosecution’s request to admit extensions of video excerpts that had been\n",
            "tendered by the Defence in order to illustrate the reason behind the presence of community\n",
            "leaders at an event depicted in the video excerpts.34\n",
            "A.2. A video and its associated transcripts and translations must be seen as\n",
            "forming integral parts of the same evidence.\n",
            "Keywords: procedure; transcripts; translation\n",
            "Transcript and translation documents are written records designed to faithfully reflect the\n",
            "contents \n",
            "---\n",
            "Filtered Page 10:\n",
            "necessary if the purpose of the video is to demonstrate ambient sound;41 the Defence in Mladić\n",
            "at the ICTY was not required to transcribe the ambient sound of a firefight in a video it\n",
            "tendered.42\n",
            "A.3. Videos not in a working language of the Court should be translated into\n",
            "one of the working languages of the Court and made available to the Chamber\n",
            "and all parties within the time limit fixed by the Chamber.\n",
            "Keywords: procedure; translation; translation accuracy; translation by counsel\n",
            "Translation\n",
            "---\n",
            "Filtered Page 11:\n",
            "the Trial Chamber ultimately found that the video did not bear ‘sufficient probative value for\n",
            "admission’.49\n",
            "Translation by Counsel. Videos adduced from other sources and devoid of translation\n",
            "and transcription can be initially translated and transcribed by counsel, so long as they are\n",
            "translated and transcribed with accuracy. The videos should be translated afterwards by a third\n",
            "party (for example, an impartial translator);50 the ICTY Trial Chamber in Mladić allowed Defence\n",
            "counsel to initially\n",
            "---\n",
            "Filtered Page 12:\n",
            "A.4. When a witness appears on a video that the party intends to tender\n",
            "into evidence, the video should be tendered through the witness during the\n",
            "examination-in-chief and not through the bar table.\n",
            "Keywords: procedure; witness evidence\n",
            "It is more appropriate for videos to be tendered during the examination-in-chief of the\n",
            "witnesses who appear in the videos. If a party wishes to present a video to a witness, it must\n",
            "first establish that the witness has personal knowledge of the making of said re\n",
            "---\n",
            "Filtered Page 13:\n",
            "in Karemera et al admitted videos which depicted violence and killings in Rwanda, but\n",
            "disregarded any accompanying comments made by journalists in the videos.61\n",
            "Nevertheless, caution should be exercised when assessing a video since differences in\n",
            "personal perception may cause difficulties in reaching a definite finding.62 It may not be\n",
            "possible to make a definite finding if a subject appears too briefly in the video.63 The ICC Trial\n",
            "Chamber in Lubanga was not able to make a definite finding on t\n",
            "---\n",
            "Filtered Page 14:\n",
            "A.6. Videos can be admitted into evidence if relevance and prima facie\n",
            "authenticity is demonstrated by providing information about the date, the\n",
            "location, the events depicted, the author, the source, and/or the chain of\n",
            "custody.\n",
            "Keyword: probative value; relevance; authenticity; chain of custody; admissibility\n",
            "Pursuant to Article 69(4) of the Rome Statute, the Court may rule on the relevance or\n",
            "admissibility of any evidence.\n",
            "Relevance. The relevance of a video depends on the date, time, and/or l\n",
            "---\n",
            "Filtered Page 15:\n",
            "Chamber in Ntaganda declined to admit a video where the Prosecution was only able to provide\n",
            "the date the video had been broadcast, but not the date the video had been shot.76\n",
            "Open Source Videos of Media Broadcasts. Features such as dates of emission, logos of\n",
            "TV programmes and images and/or voices of interviewees are sufficient indicia of reliability,\n",
            "originality, and integrity, which can lead the Court to accord higher probative value and, as a\n",
            "result, higher weight to a video. Greater weight \n",
            "---\n",
            "Filtered Page 16:\n",
            "A.7. Video evidence of interviews conducted during an armed conflict by a\n",
            "party to the conflict may not be objective and reliable and therefore low\n",
            "probative value may be attached to the video.\n",
            "Keywords: probative value; armed conflict evidence; interviews\n",
            "This Guideline refers to interviews conducted by, not with, a party to the conflict. Interviewees’\n",
            "statements taken by a party to the conflict during an armed conflict may be driven by fear,\n",
            "even if there is no corroborating evidence of intimi\n",
            "---\n",
            "Filtered Page 17:\n",
            "only be used when no acceptable alternative investigative approach is available.89 Once\n",
            "evidence has been disclosed pursuant to Article 67(2) of the Rome Statute or Rules 76 or 77\n",
            "of the ICC Rules of Procedure and Evidence, a party or participant does not have to make an\n",
            "advanced discrete application if the evidence is to be shown during investigations.90\n",
            "89 Prosecutor v Bemba (Public Redacted Decision on the Prosecution's Requests to Lift, Maintain and\n",
            "Apply Redactions to Witness Statements and\n",
            "---\n",
            "Filtered Page 18:\n",
            "B. Photographs\n",
            "Definition\n",
            "Photographs are widely used within international criminal proceedings, but despite their\n",
            "common usage, courts and tribunals have not undertaken to provide a widespread definition\n",
            "at this stage. Photographs often fall under the broad definition of documentary evidence which\n",
            "includes ‘anything in which information of any description is recorded’91 and can be defined as\n",
            "‘picture[s] made using a camera, in which an image is focused on to light-sensitive material and\n",
            "then ma\n",
            "---\n",
            "Filtered Page 19:\n",
            "B.2. Photographs can be admitted into evidence if prima facie authenticity\n",
            "is demonstrated by providing information about the date, the location, the\n",
            "events depicted, the author, the source, and/or the chain of custody.\n",
            "Keywords: probative value; relevance; authenticity; chain of custody; admissibility\n",
            "Based on Article 69(4) of the Rome Statute and Rules 63 and 64 of the ICC Rules of Procedure\n",
            "and Evidence, regarding the Court’s authority to rule on the relevance, probative value and\n",
            "admissibili\n",
            "---\n",
            "Filtered Page 20:\n",
            "Trial Chamber in Bemba also discussed this when considering two photographs, stating that\n",
            "since the Prosecution had not provided ‘any information or evidence to support their\n",
            "authenticity and reliability’, their probative value was ‘outweighed by their potential unfair\n",
            "prejudice to a fair trial’.102\n",
            "B.3. The content of photographs can be corroborated by witnesses present\n",
            "at the moment they were taken.\n",
            "Keywords: relevance, probative value; witnesses; contemporaneity\n",
            "Where photographic evidence is\n",
            "---\n",
            "Filtered Page 21:\n",
            "caused by the angle of photography.108 Exposure to such software undermined the reliability\n",
            "of photographs as they were no longer submitted in their original form.\n",
            "B.4. The consent of witnesses and others affected by the work of the Court\n",
            "whose image is depicted in photographic evidence is required.\n",
            "Keywords: prejudice; privacy; consent\n",
            "Pursuant to Article 68(1) of the Rome Statute, the Court shall take appropriate measures to\n",
            "protect the safety, physical and psychological well-being, dignity an\n",
            "---\n",
            "Filtered Page 22:\n",
            "C. Aerial and Satellite Images\n",
            "Definition\n",
            "Although Courts and Tribunals do not provide a standardised definition of this type of DDE,\n",
            "the term ‘satellite images’ has been used to describe digitally transmitted images taken by\n",
            "artificial satellites orbiting the Earth115 and the term ‘aerial images’ has been used to describe\n",
            "images taken from the sky by aircrafts or drones (also known as Unmanned Aerial Vehicles\n",
            "(UAVs).116\n",
            "C.1. Where forensic evidence including aerial and satellite images is\n",
            "volum\n",
            "---\n",
            "Filtered Page 23:\n",
            "C.2. Aerial and satellite images admitted during former witness testimony\n",
            "are admissible if they form an inseparable and indispensable part of that\n",
            "testimony.\n",
            "Keywords: procedure; former testimony; experts; witnesses\n",
            "Pursuant to Rule 92 bis (D) of the ICTY Rules of Procedure and Evidence,120 ‘a Chamber may\n",
            "admit a transcript of evidence given by a witness in proceedings before the Tribunal which\n",
            "goes to proof of a matter other than the acts and conduct of the accused’. Although Rule 92\n",
            "bis (D) d\n",
            "---\n",
            "Filtered Page 24:\n",
            "the expert was a live witness whose report is highly relevant to the case and admissible under\n",
            "Rule 89 and its Guidelines on the Standards Governing the Admission of Evidence, and who\n",
            "the Defence would be able to cross-examine.126 Once it is shown that the authors of all reports\n",
            "qualify as experts, that the evidence has probative value and relevance, and that the evidence\n",
            "helps provide a complete picture, former expert evidence can be admitted (including the\n",
            "images attached to the reports).127 T\n",
            "---\n",
            "Filtered Page 25:\n",
            "C.4. Aerial and satellite images can be used to corroborate other evidence.\n",
            "Keywords: relevance; corroboration\n",
            "Aerial and satellite images can be used to corroborate other evidence such as forensic\n",
            "evidence,132 witness testimony,133 and the reliability of intercept communications.134 The ICTY\n",
            "in Krstić found that aerial images of a purported grave site corroborated real evidence and a\n",
            "forensic report showing disturbances in the grave soil demonstrated that the bodies of those\n",
            "massacred had been \n",
            "---\n",
            "Filtered Page 26:\n",
            "credibility is safeguarded if accompanied by expert reports locating the places/individuals\n",
            "depicted.140\n",
            "Errors. The overall weight of aerial and satellite images is not adversely affected by\n",
            "technical errors or the markings and removal of certain data such as site code or coordinates,\n",
            "particularly when authenticated by witness/expert corroboration.141 The ICTY in Popović found\n",
            "that the erasure of certain dates, marked initially in white and subsequently with a coloured\n",
            "pen, did not deprive aeri\n",
            "---\n",
            "Filtered Page 27:\n",
            "D. Intercepts\n",
            "Definition\n",
            "Intercepts fall under documentary evidence and can be characterised as ‘anything in which\n",
            "information of any description is recorded.’147 Intercepts are audio communications\n",
            "intercepted using technical equipment148 which are transcribed into writing, audiotapes or any\n",
            "other type of digital records.149\n",
            "D.1. Intercepts can be tendered from the bar table if they are relevant and\n",
            "probative, and can be used to reduce the number of witnesses required, and/or\n",
            "corroborate other \n",
            "---\n",
            "Filtered Page 28:\n",
            "found that counsel could file a bar table motion for its intercept operator evidence in advance\n",
            "of calling witnesses for that section of its case, and by doing so reducing the number of\n",
            "witnesses that needed to be called upon to testify about intercept evidence.153\n",
            "Bar Table Intercepts Tendered to Corroborate Other Intercepts. Intercepts tendered\n",
            "from the bar table need not be admitted if only used to explain the probative value and the\n",
            "relevance of other intercepts. In Mladić, the ICTY Prosecut\n",
            "---\n",
            "Filtered Page 29:\n",
            "probative value of the intercepts, such that it was not substantially outweighed by the need to\n",
            "ensure a fair trial.158\n",
            "Original Intercepted Audio Recordings. It is not necessary for the Court to have access\n",
            "to the original audio recordings of intercepts when enough evidence surrounding the\n",
            "intercepts already exists.159 This mirrors the ‘best evidence rule’, meaning that ‘the Trial\n",
            "Chamber will rely on the best evidence available in the circumstances’.160 The ICTY Trial\n",
            "Chamber in Blagojević and\n",
            "---\n",
            "Filtered Page 30:\n",
            "in Tolimir held, concerning intercepted radio communications, that independent corroboration\n",
            "and overwhelming weight of other evidence served to establish the intercepts’ reliability and\n",
            "authenticity in spite of a theoretical possibility that the intercepts had been tampered with.166\n",
            "Internal Means of Corroboration. Intercepts are more likely to be deemed reliable by a\n",
            "Court when they can be authenticated, cross checked and corroborated through internal\n",
            "means such as multiple operators intercept\n",
            "---\n",
            "Filtered Page 31:\n",
            "the Trial Chamber may nevertheless take a comprehensive approach and admit them: in Mladić,\n",
            "it found that the intercepts related to the Srebrenica section of the Prosecution’s case, some\n",
            "of which were ambiguous on their own, constituted a contemporaneous, chronological record\n",
            "of events on the ground and demonstrated a network of interaction and exchange of\n",
            "information concerning the alleged crimes charged in the Indictment.173 As a result, they were\n",
            "relevant. However, the weight the Chamber will\n",
            "---\n",
            "Filtered Page 32:\n",
            "D.4. Relevance of intercepts, which are not in a working language of the\n",
            "Court, may not be assessed when there is no relevant and accurate translation.\n",
            "Not all mistakes in translations or transcripts are material or affect the\n",
            "substance and understanding of the document.\n",
            "Keywords: relevance; probative value; prejudice; translation; transcription\n",
            "The relevance of an intercept cannot be demonstrated if there is no translation available. The\n",
            "ICTY Trial Chamber in Tolimir held that since there was n\n",
            "---\n",
            "Filtered Page 33:\n",
            "The argument regarding interpretation goes to the weight, not admissibility (which is to be\n",
            "assessed at a later stage) in light of the totality of the evidence.185\n",
            "Mistakes in Translations and Transcriptions. Not all mistakes in translations or\n",
            "transcripts of intercepted communication are material or impact the substance or\n",
            "understanding of the document.186 Typographical mistakes do not make transcripts or\n",
            "translations of communication inadmissible if they are corroborated by other evidence.187 \n",
            "---\n",
            "Filtered Page 34:\n",
            "grade and amateur grade manufactured devices: military devices are always more sensitive,\n",
            "and need to meet other challenges, like the configuration of the land, weather, and/or the way\n",
            "in which they are being used. Whilst the ABiH’s equipment may not have been military grade,\n",
            "it was still able to hear participants that were far away.191 As a result, the intercepts did have\n",
            "probative value; nonetheless, the Trial Chamber treated them with caution, and considered\n",
            "whether there was corroboration or\n",
            "---\n",
            "Filtered Page 35:\n",
            "evaluation of the evidence concerning specific topics, names and locations.198 The ICC noted\n",
            "that the reliability of the recording depends on the type of information the Chamber is relying\n",
            "on, and that the Court does not rely on recordings in isolation but rather reviews all\n",
            "corresponding material together.199\n",
            "D.7. Transcripts of intercepts may be considered prima facie relevant and\n",
            "probative even when discrepancies exist between their handwritten and\n",
            "electronically typed versions.\n",
            "Keywords: rel\n",
            "---\n",
            "Filtered Page 36:\n",
            "D.8. The collection of intercepted communication evidence will not\n",
            "constitute a violation of privacy if it is provided for by law, necessary, and\n",
            "proportionate.\n",
            "Keywords: prejudice; privacy\n",
            "Pursuant to Article 69(7) of the Rome Statute, evidence obtained in violation of the ICC’s\n",
            "statutory scheme or international human rights is not admissible. The admission of such\n",
            "evidence would be antithetical to and would seriously damage the integrity of the proceedings.\n",
            "The collection of intercepted commun\n",
            "---\n",
            "Filtered Page 37:\n",
            "talkie and simultaneously recorded by a journalist on a small Sony tape)208 recorded ‘by\n",
            "eavesdropping on an enemy’s telephone calls during the course of a war’ was ‘certainly not\n",
            "within the conduct which is referred to in Rule 95’. However, the ICTR Trial Chamber\n",
            "determined it was not ‘antithetical to and certainly would not seriously damage the integrity of\n",
            "the proceedings’.209 The ICTR Trial Chamber found that the telephone call could be admitted,\n",
            "particularly in light of the fact that the jo\n",
            "---\n",
            "Filtered Page 38:\n",
            "the integrity of the proceedings, will determine their admissibility.217 The ICTY Trial Chamber,\n",
            "moreover, found that its jurisprudence had never endorsed the exclusionary rule as a matter\n",
            "of principle.218 Particularly in situations of armed conflict, intelligence which may be the result\n",
            "of illegal activity may prove to be essential in uncovering the truth; particularly when this\n",
            "information is not available from other sources.219 In applying the provisions of Rule 95, the\n",
            "Tribunal considered al\n",
            "---\n",
            "Filtered Page 39:\n",
            "of communications protected by privilege as envisaged in the Court’s legal framework would\n",
            "not be accessed by the Prosecution.’224\n",
            "224 Prosecutor v Bemba et al (Judgment on the appeals of Mr Jean-Pierre Bemba Gombo, Mr Aimé Kilolo\n",
            "Musamba, Mr Jean-Jacques Mangenda Kabongo, Mr Fidèle Babala and Mr Narcisse Arido against the\n",
            "Decision of Trial Chamber VII entitled “Judgment pursuant to Article 74 of the Statute”) ICC-01/05-\n",
            "01/13-2275-Red (8 March 2018) (AC) [455].\n",
            "41\n",
            "---\n",
            "Filtered Page 40:\n",
            "E. Call Data Records\n",
            "Definition\n",
            "Call Data Records (CDRs) are defined as metadata that do not contain the content of any\n",
            "communications, but solely provide information about them, such as the source and\n",
            "destination phone numbers, date and time of phone calls and text messages, the type of\n",
            "communication, the duration of phone calls, the IMEI number225 of the handset relevant to the\n",
            "communications, and the cell sectors226 engaged at the beginning and end of a call.227\n",
            "Call Sequence Tables (CSTs) ar\n",
            "---\n",
            "Filtered Page 41:\n",
            "Instead, the CDRs should be rendered intelligible through Call Sequence Tables (CSTs).\n",
            "The STL Prosecution in Ayyash et al produced a CST presenting a chronological sequence of\n",
            "calls relating to a target telephone number over a specified period of time, comprising relevant\n",
            "CDR information including: the other telephone number in contact with the target telephone\n",
            "number, the time and date of the call, the type of call and duration, the IMEI number231 of the\n",
            "handset used by the target number, and \n",
            "---\n",
            "Filtered Page 42:\n",
            "Disclosure of Related Documents. Pursuant to Rule 71(B) of the IRMCT Rules of\n",
            "Procedure and Evidence, the Prosecutor shall permit the Defence to inspect any books,\n",
            "documents, photographs, and tangible objects in the Prosecutor’s custody or control which are\n",
            "material to the preparation of the defence or intended for use at trial.239 This establishes the\n",
            "scope of the Prosecutor’s disclosure obligations. The MICT Single Judge in Turinabo et al held\n",
            "that in addition to the CDRs, the following relate\n",
            "---\n",
            "Filtered Page 43:\n",
            "communications evidence. The ICC Trial Chamber in Bemba et al found that call data reinforced\n",
            "and confirmed the accuracy of the intercepted communications as they were consistent with\n",
            "each other.243 Conversely, the Defence in Nzabonimpa et al before the MICT sought to use call\n",
            "data to discount the reliability of intercepted communications by highlighting discrepancies\n",
            "between the durations of the intercepted communications and the durations of the phone calls\n",
            "indicated in the call data.244\n",
            "CDRs \n",
            "---\n",
            "Filtered Page 44:\n",
            "their content is of no practical utility in its raw form.249 Instead, the tendering party should\n",
            "provide contextual evidence on its chain of custody, including evidence on the creation,\n",
            "storage, and retrieval of the CDRs.250 The CDRs themselves may also have inherent indicia of\n",
            "authenticity, such as the corporate watermarks of the telecommunications provider.251 For\n",
            "example, some of the CDRs tendered in Bemba et al had a ‘kpn Group Belgium’ watermark.252\n",
            "Reliability of CSTs. The tendering party \n",
            "---\n",
            "Filtered Page 45:\n",
            "telecommunications provider or self-identification at the start of intercepted calls;258\n",
            "intercepted communications which matched the corresponding call data;259 expert testimony\n",
            "on the origins of the CDRs;260 and a case record containing information confirming the\n",
            "authenticity and chain of custody of the CDRs.261\n",
            "E.5. The collection and transfer of Call Data Records will not constitute a\n",
            "violation of international human rights standards regarding privacy if the\n",
            "collection and transfer are provi\n",
            "---\n",
            "Filtered Page 46:\n",
            "second, the national authority’s subsequent authorisation to carry out the requested\n",
            "collection.264 The former is based on the Prosecutor’s powers with respect to investigations\n",
            "under Article 54(3) of the Rome Statute or the Court’s authority to make requests to States\n",
            "Parties for cooperation under Article 87(1) of the Rome Statute, whereas the latter is regulated\n",
            "by the domestic law applicable to the national authority.265\n",
            "Other legal grounds are available. For example, the ICC Appeals Chamber \n",
            "---\n",
            "Filtered Page 47:\n",
            "Call Sequence Tables (CSTs) with which to construct the case and file the indictments against\n",
            "the accused.270\n",
            "Proportionality. The proportionality of the collection of the CDRs is assessed with\n",
            "reference to a number of factors. In Bemba et al, the collection of CDRs was held by the ICC\n",
            "Trial Chamber to be proportionate because they only concerned non-privileged calls and not\n",
            "calls that were protected by attorney-client privilege.271 In concluding that the transfer of CDRs\n",
            "was proportionate, the \n",
            "---\n",
            "Filtered Page 48:\n",
            "F. Audio Recordings\n",
            "Definition\n",
            "Audio recordings are recordings ‘made on any disc, tape or other device on which sounds are\n",
            "recorded so as to be capable of being reproduced’.274 For the purposes of these Guidelines,\n",
            "audio recordings are not intercepted.\n",
            "F.1. Instead of excerpts, audio recordings should be submitted in their\n",
            "entirety.\n",
            "Keywords: procedure; excerpts\n",
            "Submission of full recordings, transcripts, and translations assist judges in contextualising the\n",
            "segments of the recording identified \n",
            "---\n",
            "Filtered Page 49:\n",
            "F.2. Audio recordings of media broadcasts are relevant if they refer to\n",
            "events that took place during the time period relevant to the charges and are\n",
            "contemporaneous with the events.\n",
            "Keywords: relevance; media broadcasts; contemporaneity\n",
            "Audio recordings of media broadcasts should be contemporaneous to the events they purport\n",
            "to demonstrate. The ICC Trial Chamber in Bemba found that audio recording CAR-OTP-0031-\n",
            "0099 (a Radio France Internationale programme concerning the situation in the Centra\n",
            "---\n",
            "Filtered Page 50:\n",
            "CAR-OTP-0031-0099 (a Radio France Internationale programme concerning the situation in\n",
            "the Central African Republic dated 5 December 2002) could ‘serve to corroborate other pieces\n",
            "of evidence and might be examined when assessing the prosecution's allegation that the\n",
            "conduct described in the charges was widely broadcast which, according to the prosecution,\n",
            "may have implications with regard to the accused's alleged knowledge of the crimes\n",
            "charged.’280 In light of the envisioned limited usage of th\n",
            "---\n",
            "Filtered Page 51:\n",
            "Open Source Audio Recordings of Media Broadcasts. The ICC Trial Chamber in Bemba\n",
            "held that where the audio recording of an interview lacks a date and contains no questions, the\n",
            "tendering party must provide sufficient information to identify the recorded voice and ‘to\n",
            "confirm the date, circumstances and context in which the recording was created’.285 In the\n",
            "absence of such information, the ICC Trial Chamber found that it could not afford probative\n",
            "value to audio recording CAR-DEF-0001-0830, which\n",
            "---\n",
            "Filtered Page 52:\n",
            "F.5. Insufficient authentication goes to the weight of audio recordings\n",
            "rather than their admissibility.\n",
            "Keywords: relevance; probative value; hearsay; admissibility\n",
            "Pursuant to Rule 92 bis of the SCSL Rules of Procedure and Evidence, a Chamber may, in lieu\n",
            "of oral testimony, admit information including written statements and transcripts that do not\n",
            "go to proof of the acts and conduct of the accused. Such information should be ‘relevant to\n",
            "the purpose for which it is submitted and its reliabilit\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pdfplumber\n",
        "\n",
        "def extract_sections_and_subsections(pdf_path):\n",
        "    # Regex patterns for sections and subsections\n",
        "    section_pattern = r\"^(?P<header>[A-Z]\\.\\s.+)\"  # Match main sections like \"A. Videos\"\n",
        "    subsection_pattern = r\"^(?P<subheader>[A-Z]\\d+\\.\\s*.+)\"\n",
        "    extracted_sections = []\n",
        "    content_to_process = \"\"\n",
        "    start_processing = False\n",
        "\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            text = page.extract_text()\n",
        "\n",
        "            if not start_processing:\n",
        "                # Skip the Table of Contents\n",
        "                if \"Table of Contents\" in text:\n",
        "                    continue\n",
        "\n",
        "                # Look for the start marker (\"I. Introduction\" in this case)\n",
        "                match = re.search(r\"\\bI\\. Introduction\\b\", text, re.IGNORECASE)\n",
        "                if match:\n",
        "                    start_processing = True\n",
        "                    _, remaining_text = re.split(r\"\\bI\\. Introduction\\b\", text, flags=re.IGNORECASE, maxsplit=1)\n",
        "                    content_to_process += remaining_text.strip()\n",
        "            else:\n",
        "                # Append remaining text from the document\n",
        "                content_to_process += \"\\n\" + text.strip()\n",
        "\n",
        "    # Process text to extract sections and subsections\n",
        "    lines = content_to_process.splitlines()\n",
        "    current_section = None\n",
        "    current_text = []\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "\n",
        "        # Match a main section header\n",
        "        section_match = re.match(section_pattern, line)\n",
        "        if section_match:\n",
        "            # Save the previous section and its text\n",
        "            if current_section:\n",
        "                extracted_sections.append({\"header\": current_section, \"text\": \"\\n\".join(current_text)})\n",
        "\n",
        "            # Start a new section\n",
        "            current_section = section_match.group(\"header\")\n",
        "            current_text = []\n",
        "            continue\n",
        "\n",
        "        # Match a subsection header\n",
        "        subsection_match = re.match(subsection_pattern, line)\n",
        "        if subsection_match:\n",
        "            # Save the current section and start a new subsection\n",
        "            if current_section:\n",
        "                extracted_sections.append({\"header\": current_section, \"text\": \"\\n\".join(current_text)})\n",
        "            current_section = subsection_match.group(\"subheader\")\n",
        "            current_text = []\n",
        "            continue\n",
        "\n",
        "        # Accumulate text under the current header\n",
        "        if current_section:\n",
        "            current_text.append(line)\n",
        "\n",
        "    # Append the last section\n",
        "    if current_section:\n",
        "        extracted_sections.append({\"header\": current_section, \"text\": \"\\n\".join(current_text)})\n",
        "\n",
        "    return extracted_sections\n",
        "\n",
        "# Example Usage\n",
        "sections = extract_sections_and_subsections(pdf_path=pdf_path)\n",
        "\n",
        "# Display results\n",
        "for section in sections:\n",
        "    print(f\"Header: {section['header']}\")\n",
        "    print(f\"Text: {section['text'][:200]}...\")  # Display first 200 chars of text\n",
        "    print(\"---\")"
      ],
      "metadata": {
        "id": "pC7IwAn_osy8",
        "outputId": "953f4163-7bac-435f-8261-d99e0273a8ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Header: A. Definition of DDE\n",
            "Text: The term ‘Digitally Derived Evidence’ was coined by the DDE Project to encompass both\n",
            "‘digital evidence,’ which is material that has been “born-digital” in the sense of originating from\n",
            "1 Internationa...\n",
            "---\n",
            "Header: B. Methodology\n",
            "Text: The Guidelines are based on an in-depth analysis of the jurisprudence of the international\n",
            "criminal courts and tribunals. They draw on the findings set out in the DDE Project's\n",
            "extensive Case Summarie...\n",
            "---\n",
            "Header: C. Structure of the Leiden Guidelines\n",
            "Text: The Leiden Guidelines address each type of DDE separately in order to take into account their\n",
            "technological and legal particularities. Each section begins with a definition of the DDE\n",
            "category. In so ...\n",
            "---\n",
            "Header: D. Scope of the Leiden Guidelines\n",
            "Text: The rules and practice surrounding the use of DDE in international criminal courts and tribunals\n",
            "continue to develop. Digital technology is being used more widely and frequently, not only in\n",
            "the inves...\n",
            "---\n",
            "Header: A. Videos\n",
            "Text: Definition\n",
            "The international courts and tribunals do not define the concept of videos. However, in general\n",
            "terms, video recordings are commonly referred to as ‘audio-visual material’28 and as such,\n",
            "vi...\n",
            "---\n",
            "Header: B. Photographs\n",
            "Text: Definition\n",
            "Photographs are widely used within international criminal proceedings, but despite their\n",
            "common usage, courts and tribunals have not undertaken to provide a widespread definition\n",
            "at this st...\n",
            "---\n",
            "Header: C. Aerial and Satellite Images\n",
            "Text: Definition\n",
            "Although Courts and Tribunals do not provide a standardised definition of this type of DDE,\n",
            "the term ‘satellite images’ has been used to describe digitally transmitted images taken by\n",
            "artif...\n",
            "---\n",
            "Header: D. Intercepts\n",
            "Text: Definition\n",
            "Intercepts fall under documentary evidence and can be characterised as ‘anything in which\n",
            "information of any description is recorded.’147 Intercepts are audio communications\n",
            "intercepted usi...\n",
            "---\n",
            "Header: E. Call Data Records\n",
            "Text: Definition\n",
            "Call Data Records (CDRs) are defined as metadata that do not contain the content of any\n",
            "communications, but solely provide information about them, such as the source and\n",
            "destination phone n...\n",
            "---\n",
            "Header: F. Audio Recordings\n",
            "Text: Definition\n",
            "Audio recordings are recordings ‘made on any disc, tape or other device on which sounds are\n",
            "recorded so as to be capable of being reproduced’.274 For the purposes of these Guidelines,\n",
            "audio...\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "-epEPaNMyweF",
        "outputId": "5190b621-aa96-4551-d902-ec0185c3e56b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'header': 'Unknown Header', 'content': 'F'}, {'header': 'Unknown Header', 'content': '.'}, {'header': 'Unknown Header', 'content': '5'}, {'header': 'Unknown Header', 'content': '.'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'I'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 'f'}, {'header': 'Unknown Header', 'content': 'f'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'h'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'g'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'h'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'w'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'g'}, {'header': 'Unknown Header', 'content': 'h'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'f'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 'g'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'h'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'h'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'h'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': 'm'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'b'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'l'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'y'}, {'header': 'Unknown Header', 'content': '.'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'K'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'y'}, {'header': 'Unknown Header', 'content': 'w'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': ':'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'l'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'v'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': ';'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'p'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'b'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'v'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'v'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'l'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': ';'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'h'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'y'}, {'header': 'Unknown Header', 'content': ';'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': 'm'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'b'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'l'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'y'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'P'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'R'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 'l'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': '9'}, {'header': 'Unknown Header', 'content': '2'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'b'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'f'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'h'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'S'}, {'header': 'Unknown Header', 'content': 'C'}, {'header': 'Unknown Header', 'content': 'S'}, {'header': 'Unknown Header', 'content': 'L'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'R'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 'l'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'f'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'P'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'E'}, {'header': 'Unknown Header', 'content': 'v'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': ','}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'C'}, {'header': 'Unknown Header', 'content': 'h'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'm'}, {'header': 'Unknown Header', 'content': 'b'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'm'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'y'}, {'header': 'Unknown Header', 'content': ','}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'l'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'f'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'l'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'm'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 'y'}, {'header': 'Unknown Header', 'content': ','}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': 'm'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 'f'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'm'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 'l'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 'g'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'w'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'm'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'p'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'h'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'g'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'p'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'f'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'f'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'h'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'f'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'h'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': '.'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'S'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 'h'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 'f'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'm'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 'h'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 'l'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'b'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': '‘'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'l'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'v'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'h'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'p'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'p'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'f'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'w'}, {'header': 'Unknown Header', 'content': 'h'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 'h'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 'b'}, {'header': 'Unknown Header', 'content': 'm'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'l'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'b'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'l'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'y'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 'h'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 'l'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'b'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'p'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'b'}, {'header': 'Unknown Header', 'content': 'l'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'f'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 'f'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'm'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': '’'}, {'header': 'Unknown Header', 'content': '.'}, {'header': 'Unknown Header', 'content': '2'}, {'header': 'Unknown Header', 'content': '9'}, {'header': 'Unknown Header', 'content': '2'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'A'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 'g'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'h'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 'f'}, {'header': 'Unknown Header', 'content': 'f'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'l'}, {'header': 'Unknown Header', 'content': 'y'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'g'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'f'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': ','}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 'm'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 'l'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'v'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': '/'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'h'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'l'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 'g'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'f'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'm'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 'y'}, {'header': 'Unknown Header', 'content': 'm'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'h'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'y'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'm'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'y'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'v'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'h'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'l'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'b'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': 'm'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': '.'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'C'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'q'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'l'}, {'header': 'Unknown Header', 'content': 'y'}, {'header': 'Unknown Header', 'content': ','}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'h'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'D'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'f'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'T'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'y'}, {'header': 'Unknown Header', 'content': 'l'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'g'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'b'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'f'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'h'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'S'}, {'header': 'Unknown Header', 'content': 'C'}, {'header': 'Unknown Header', 'content': 'S'}, {'header': 'Unknown Header', 'content': 'L'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'h'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 'g'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'f'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'B'}, {'header': 'Unknown Header', 'content': 'B'}, {'header': 'Unknown Header', 'content': 'C'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'b'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'w'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': 'm'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'b'}, {'header': 'Unknown Header', 'content': 'l'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': '.'}, {'header': 'Unknown Header', 'content': '2'}, {'header': 'Unknown Header', 'content': '9'}, {'header': 'Unknown Header', 'content': '3'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'H'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'w'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'v'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': ','}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'h'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'S'}, {'header': 'Unknown Header', 'content': 'C'}, {'header': 'Unknown Header', 'content': 'S'}, {'header': 'Unknown Header', 'content': 'L'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'T'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'l'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'C'}, {'header': 'Unknown Header', 'content': 'h'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'm'}, {'header': 'Unknown Header', 'content': 'b'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': 'm'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'h'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'v'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'R'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 'l'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': '9'}, {'header': 'Unknown Header', 'content': '2'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'b'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'h'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'l'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'h'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'h'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'D'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'f'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'b'}, {'header': 'Unknown Header', 'content': 'j'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'w'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'w'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'g'}, {'header': 'Unknown Header', 'content': 'h'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': 'm'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'b'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'l'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'y'}, {'header': 'Unknown Header', 'content': '.'}, {'header': 'Unknown Header', 'content': '2'}, {'header': 'Unknown Header', 'content': '9'}, {'header': 'Unknown Header', 'content': '4'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': '2'}, {'header': 'Unknown Header', 'content': '9'}, {'header': 'Unknown Header', 'content': '2'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'R'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 'l'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': '9'}, {'header': 'Unknown Header', 'content': '2'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'b'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'f'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'h'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'S'}, {'header': 'Unknown Header', 'content': 'C'}, {'header': 'Unknown Header', 'content': 'S'}, {'header': 'Unknown Header', 'content': 'L'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'R'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 'l'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'f'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'P'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'E'}, {'header': 'Unknown Header', 'content': 'v'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': '.'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': '2'}, {'header': 'Unknown Header', 'content': '9'}, {'header': 'Unknown Header', 'content': '3'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'P'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'v'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'T'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'y'}, {'header': 'Unknown Header', 'content': 'l'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': '('}, {'header': 'Unknown Header', 'content': 'D'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'P'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'M'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'f'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'A'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': 'm'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'f'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'B'}, {'header': 'Unknown Header', 'content': 'B'}, {'header': 'Unknown Header', 'content': 'C'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'R'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'B'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': ')'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'S'}, {'header': 'Unknown Header', 'content': 'C'}, {'header': 'Unknown Header', 'content': 'S'}, {'header': 'Unknown Header', 'content': 'L'}, {'header': 'Unknown Header', 'content': '-'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': '0'}, {'header': 'Unknown Header', 'content': '3'}, {'header': 'Unknown Header', 'content': '-'}, {'header': 'Unknown Header', 'content': '0'}, {'header': 'Unknown Header', 'content': '1'}, {'header': 'Unknown Header', 'content': '-'}, {'header': 'Unknown Header', 'content': 'T'}, {'header': 'Unknown Header', 'content': '-'}, {'header': 'Unknown Header', 'content': '7'}, {'header': 'Unknown Header', 'content': '4'}, {'header': 'Unknown Header', 'content': '5'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': '('}, {'header': 'Unknown Header', 'content': '2'}, {'header': 'Unknown Header', 'content': '5'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'F'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'b'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'y'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': '2'}, {'header': 'Unknown Header', 'content': '0'}, {'header': 'Unknown Header', 'content': '0'}, {'header': 'Unknown Header', 'content': '9'}, {'header': 'Unknown Header', 'content': ')'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': '('}, {'header': 'Unknown Header', 'content': 'T'}, {'header': 'Unknown Header', 'content': 'C'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'I'}, {'header': 'Unknown Header', 'content': 'I'}, {'header': 'Unknown Header', 'content': ')'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': '['}, {'header': 'Unknown Header', 'content': '7'}, {'header': 'Unknown Header', 'content': ']'}, {'header': 'Unknown Header', 'content': '.'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': '2'}, {'header': 'Unknown Header', 'content': '9'}, {'header': 'Unknown Header', 'content': '4'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'P'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'v'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'T'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'y'}, {'header': 'Unknown Header', 'content': 'l'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': '('}, {'header': 'Unknown Header', 'content': 'D'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'P'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'M'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'f'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'A'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': 'm'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'n'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'f'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'B'}, {'header': 'Unknown Header', 'content': 'B'}, {'header': 'Unknown Header', 'content': 'C'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'R'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': 'i'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'B'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'o'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'd'}, {'header': 'Unknown Header', 'content': 'c'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': 't'}, {'header': 'Unknown Header', 'content': 's'}, {'header': 'Unknown Header', 'content': ')'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'S'}, {'header': 'Unknown Header', 'content': 'C'}, {'header': 'Unknown Header', 'content': 'S'}, {'header': 'Unknown Header', 'content': 'L'}, {'header': 'Unknown Header', 'content': '-'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': '0'}, {'header': 'Unknown Header', 'content': '3'}, {'header': 'Unknown Header', 'content': '-'}, {'header': 'Unknown Header', 'content': '0'}, {'header': 'Unknown Header', 'content': '1'}, {'header': 'Unknown Header', 'content': '-'}, {'header': 'Unknown Header', 'content': 'T'}, {'header': 'Unknown Header', 'content': '-'}, {'header': 'Unknown Header', 'content': '7'}, {'header': 'Unknown Header', 'content': '4'}, {'header': 'Unknown Header', 'content': '5'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': '('}, {'header': 'Unknown Header', 'content': '2'}, {'header': 'Unknown Header', 'content': '5'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'F'}, {'header': 'Unknown Header', 'content': 'e'}, {'header': 'Unknown Header', 'content': 'b'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'u'}, {'header': 'Unknown Header', 'content': 'a'}, {'header': 'Unknown Header', 'content': 'r'}, {'header': 'Unknown Header', 'content': 'y'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': '2'}, {'header': 'Unknown Header', 'content': '0'}, {'header': 'Unknown Header', 'content': '0'}, {'header': 'Unknown Header', 'content': '9'}, {'header': 'Unknown Header', 'content': ')'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': '('}, {'header': 'Unknown Header', 'content': 'T'}, {'header': 'Unknown Header', 'content': 'C'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': 'I'}, {'header': 'Unknown Header', 'content': 'I'}, {'header': 'Unknown Header', 'content': ')'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': '['}, {'header': 'Unknown Header', 'content': '2'}, {'header': 'Unknown Header', 'content': '7'}, {'header': 'Unknown Header', 'content': ']'}, {'header': 'Unknown Header', 'content': '-'}, {'header': 'Unknown Header', 'content': '['}, {'header': 'Unknown Header', 'content': '2'}, {'header': 'Unknown Header', 'content': '8'}, {'header': 'Unknown Header', 'content': ']'}, {'header': 'Unknown Header', 'content': '.'}, {'header': 'Unknown Header', 'content': ''}, {'header': 'Unknown Header', 'content': '5'}, {'header': 'Unknown Header', 'content': '4'}]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "list indices must be integers or slices, not str",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-de7f9cf16648>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0msubsections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_headers_and_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubsections\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Header: {subsections['header']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Text: {subsections['content'][:200]}...\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Display first 200 chars of text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import pdfplumber\n",
        "\n",
        "def extract_headers_and_chunks(chunks):\n",
        "    headers_with_chunks = []\n",
        "\n",
        "    for chunk in chunks:\n",
        "        # Match header at the start of the chunk (e.g., C. Aerial and Satellite Images)\n",
        "        match = re.match(r\"^[A-Z](?:\\.\\d+)?\\.\\s.+\", chunk)\n",
        "        if match:\n",
        "            header = match.group(0).strip()  # Extract the header\n",
        "            content = chunk[len(header):].strip()  # Remaining content after the header\n",
        "            headers_with_chunks.append({\"header\": header, \"content\": content})\n",
        "        else:\n",
        "            headers_with_chunks.append({\"header\": \"Unknown Header\", \"content\": chunk.strip()})\n",
        "\n",
        "    return headers_with_chunks\n",
        "\n",
        "for section in sections:\n",
        "    subsections = extract_headers_and_chunks(section['text'])\n",
        "    print(subsections)\n",
        "    print(f\"Header: {subsections['header']}\")\n",
        "    print(f\"Text: {subsections['content'][:200]}...\")  # Display first 200 chars of text\n",
        "    print(\"---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qboTjRY8rCS",
        "outputId": "0016839d-e4a1-44d0-a0dc-3dd277ced3f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Section Header: Unknown Header\n",
            "\n",
            "Section Header: A. Definition of DDE\n",
            "\n",
            "Section Header: B. Methodology\n",
            "\n",
            "Section Header: C. Structure of the Leiden Guidelines\n",
            "\n",
            "Section Header: D. Scope of the Leiden Guidelines\n",
            "\n",
            "Section Header: A. Videos\n",
            "\n",
            "Section Header: B. Photographs\n",
            "\n",
            "Section Header: C. Aerial and Satellite Images\n",
            "\n",
            "Section Header: D. Intercepts\n",
            "\n",
            "Section Header: E. Call Data Records\n",
            "\n",
            "Section Header: F. Audio Recordings\n",
            "\n"
          ]
        }
      ],
      "source": [
        "headers_with_chunks = extract_headers_and_chunks(chunks)\n",
        "\n",
        "for item in headers_with_chunks:\n",
        "    print(f\"Section Header: {item['header']}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4ZDnQNeDWuV"
      },
      "outputs": [],
      "source": [
        "import chromadb\n",
        "\n",
        "# vecorisation could be improved\n",
        "\n",
        "class DocumentProcessor:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the document processor with necessary components.\"\"\"\n",
        "        # Set up embedding model\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "        self.model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "        self.model.eval()\n",
        "        # Initialize document converter\n",
        "        self.md = MarkItDown()\n",
        "        # Set up vector database\n",
        "        self.vector_db = chromadb.Client()\n",
        "        self.collection = self.vector_db.get_or_create_collection(name=\"legal_docs\")\n",
        "\n",
        "    def process_document(self, file_path):\n",
        "        \"\"\"Convert document to text and generate embeddings.\"\"\"\n",
        "        try:\n",
        "            pdf_processor = PDFProccessor(file_path)\n",
        "            # Convert document to text\n",
        "            conversion_result = self.md.convert(file_path)\n",
        "            conversion_result_text = self.md.convert(file_path).text_content\n",
        "            # TODO - teh leiden guidelines contain a section of keywwords for each section - these should be parsed out and each section should be stored seperately\n",
        "            conversion_result_text = pdf_processor.remove_page_numbers(conversion_result_text)\n",
        "            print(conversion_result)\n",
        "\n",
        "            # Create embeddings\n",
        "            inputs = self.tokenizer(\n",
        "                conversion_result_text,\n",
        "                return_tensors=\"pt\",\n",
        "                truncation=True\n",
        "            )\n",
        "            # Use GPU if available\n",
        "            if torch.cuda.is_available():\n",
        "                self.model.to('cuda')\n",
        "                inputs = {k: v.to('cuda') for k, v in inputs.items()}\n",
        "            # Generate embeddings\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy().tolist()\n",
        "            # **************\n",
        "            return {\n",
        "                'text': conversion_result_text,\n",
        "                'embeddings': embeddings,\n",
        "                'metadata': {}\n",
        "            }\n",
        "            # Note: we don't seem to get metadata from the docs anyway so better manually adding\n",
        "            getattr(conversion_result, 'metadata', {})\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error processing document {file_path}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def store_document(self, doc_id, text, embedding, metadata=None):\n",
        "        \"\"\"Store document in the vector database.\"\"\"\n",
        "        if metadata is None:\n",
        "            metadata = {}\n",
        "        self.collection.add(\n",
        "            documents=[text],\n",
        "            embeddings=[embedding],\n",
        "            metadatas=[metadata],\n",
        "            ids=[doc_id]\n",
        "        )\n",
        "\n",
        "    def find_relevant_documents(self, query, metadata_titles, metadata_keywords, n_results=3):\n",
        "        \"\"\"Find relevant documents for a given query.\"\"\"\n",
        "\n",
        "        filter_dict = {}\n",
        "\n",
        "        if metadata_titles and len(metadata_titles) > 0:\n",
        "          filter_dict[\"title\"] = {\"$in\": metadata_titles}\n",
        "\n",
        "        if metadata_keywords:\n",
        "          filter_dict[\"keywords\"] = {\"$in\": metadata_keywords}\n",
        "\n",
        "        filter = None if len(filter_dict) == 0 else filter_dict\n",
        "\n",
        "        results = self.collection.query(\n",
        "            query_texts=[query],\n",
        "            where=filter,\n",
        "            n_results=n_results\n",
        "        )\n",
        "        return [\n",
        "            {\n",
        "                'text': doc_text,\n",
        "                'id': results['ids'][0][i],\n",
        "                'metadata': results['metadatas'][0][i]\n",
        "            }\n",
        "            for i, doc_text in enumerate(results['documents'][0])\n",
        "        ]\n",
        "# Initialize processor\n",
        "processor = DocumentProcessor()\n",
        "# Move to GPU if available\n",
        "if torch.cuda.is_available():\n",
        "    processor.model = processor.model.to('cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkS0b_2JFRG8"
      },
      "source": [
        "Set Up LLaMA Model\n",
        "\n",
        "Go to HuggingFace and search for the llama model you want to use. For example, 3.1. Request permission to use it and get a HuggingFace token.\n",
        "\n",
        "This cell initializes the LLaMA model for generating responses:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wu9Rc0_FVt7"
      },
      "outputs": [],
      "source": [
        "# fine tune llama to make this better\n",
        "# experiment with prompts\n",
        "# open ai option\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"meta-llama/Llama-3.1-8B\",\n",
        "    token=HF_TOKEN\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"meta-llama/Llama-3.1-8B\",\n",
        "    token=HF_TOKEN\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaiYpiaDFhLW"
      },
      "source": [
        "Process Documents\n",
        "\n",
        "This cell processes all documents in your legal_documents folder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SztXztcd7VrS",
        "outputId": "f5f0131d-111f-4002-df20-15c0d6e25554"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'title': 'Leiden Guidelines on the Use of Digitally Derived Evidence in International Criminal Courts and Tribunals', 'author': 'Unknown', 'section-header': '', 'category': '', 'keywords': ''}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "metadata_list = {\n",
        "    'doc_0_Leiden Guidelines on the Use of DDE in ICCTs_20220404.pdf' : {\n",
        "      'title': 'Leiden Guidelines on the Use of Digitally Derived Evidence in International Criminal Courts and Tribunals',\n",
        "      'author': 'Unknown',\n",
        "      'section-header': '',\n",
        "      'category': '',\n",
        "      'keywords': '',\n",
        "    },\n",
        "    'doc_1_Extrapolations from Case Law on DDE in ICCTs_20220405.pdf': {\n",
        "      'title': 'Extrapolations from case law on the use of digitally derived evidence (dde) before international criminal courts and tribunals',\n",
        "      'author': 'Unknown',\n",
        "      'section-header': '',\n",
        "      'category': '',\n",
        "      'keywords': '',\n",
        "      },\n",
        "    'doc_2_Case Summaries-The Use of DDE before ICCTs.pdf': {\n",
        "      'title': 'Analysis of Digitally Derived Evidence from the Jurisprudence of International Tribunals: Cases from the ICC, ICTR, ICTY, IRMCT, SCSL and STL',\n",
        "      'author': 'Unknown',\n",
        "      'section-header': '',\n",
        "      'category': '',\n",
        "      'keywords': '',\n",
        "      },\n",
        "    'doc_3_Fact-Finding-Missions.pdf': {\n",
        "      'title': 'REPORT ON DIGITALLY DERIVED EVIDENCE USED IN UN HUMAN RIGHTS FACT-FINDING MISSIONS APPROACHES AND STANDARDS OF PROOF',\n",
        "      'author': 'Unknown',\n",
        "      'section-header': '',\n",
        "      'category': '',\n",
        "      'keywords': '',\n",
        "\n",
        "      },\n",
        "    'doc_4_DDE in ICL.pdf': {\n",
        "      'title': 'REPORT ON DIGITALLY DERIVED EVIDENCE IN INTERNATIONAL CRIMINAL LAW',\n",
        "      'author': 'Unknown',\n",
        "      'section-header': '',\n",
        "      'category': '',\n",
        "      'keywords': '',\n",
        "      },\n",
        "}\n",
        "# TODO 'section-header': '' each PDF needs chunked and the section header of each chunk need added to the metadata\n",
        "print(metadata_list['doc_0_Leiden Guidelines on the Use of DDE in ICCTs_20220404.pdf'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wv22Av64FylR",
        "outputId": "df4a945e-8329-43e3-d81b-72412695ab25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 5 documents to process\n",
            "Processing Leiden Guidelines on the Use of DDE in ICCTs_20220404.pdf...\n",
            "<markitdown._markitdown.DocumentConverterResult object at 0x78084c990790>\n",
            "✅ Finished storing Leiden Guidelines on the Use of DDE in ICCTs_20220404.pdf in Chroma\n",
            "\n",
            "Processing Extrapolations from Case Law on DDE in ICCTs_20220405.pdf...\n",
            "<markitdown._markitdown.DocumentConverterResult object at 0x78084fc52310>\n",
            "✅ Finished storing Extrapolations from Case Law on DDE in ICCTs_20220405.pdf in Chroma\n",
            "\n",
            "Processing Case Summaries-The Use of DDE before ICCTs.pdf...\n",
            "<markitdown._markitdown.DocumentConverterResult object at 0x78084ffd6690>\n",
            "✅ Finished storing Case Summaries-The Use of DDE before ICCTs.pdf in Chroma\n",
            "\n",
            "Processing Fact-Finding-Missions.pdf...\n",
            "<markitdown._markitdown.DocumentConverterResult object at 0x78084fcabb90>\n",
            "✅ Finished storing Fact-Finding-Missions.pdf in Chroma\n",
            "\n",
            "Processing DDE in ICL.pdf...\n",
            "<markitdown._markitdown.DocumentConverterResult object at 0x78084fe14390>\n",
            "✅ Finished storing DDE in ICL.pdf in Chroma\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get list of documents\n",
        "# improves the inteface\n",
        "# disclaimers - agent answers - next agent makes it accesible - next agent is a lawyer that critiques answer\n",
        "\n",
        "document_files = [\n",
        "    f for f in os.listdir(DOCUMENTS_PATH)\n",
        "    if f.endswith(('.pdf', '.docx', '.txt', '.html', '.pptx'))\n",
        "]\n",
        "if not document_files:\n",
        "    print(\"⚠️ No documents found! Add some to your legal_documents folder\")\n",
        "else:\n",
        "    print(f\"Found {len(document_files)} documents to process\")\n",
        "    for idx, document in enumerate(document_files):\n",
        "        print(f\"Processing {document}...\")\n",
        "        file_path = os.path.join(DOCUMENTS_PATH, document)\n",
        "        # Process document\n",
        "        result = processor.process_document(file_path)\n",
        "        # Store in database\n",
        "        doc_id = f\"doc_{idx}_{document}\"\n",
        "        metadata = metadata_list[doc_id]\n",
        "        processor.store_document(\n",
        "            doc_id=doc_id,\n",
        "            text=result['text'],\n",
        "            embedding=result['embeddings'],\n",
        "            metadata=metadata\n",
        "        )\n",
        "        print(f\"✅ Finished storing {document} in Chroma\\n\")\n",
        "        # except Exception as e:\n",
        "        #     print(f\"Error processing {document}: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6AC3HnbF5iu"
      },
      "source": [
        "Question-Answering Function\n",
        "\n",
        "This cell defines the function that generates answers using LLaMA. You may alter the values if you know what you’re doing :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwwDNz-9BQLV"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "# Sample function for extracting keywords\n",
        "def extract_keywords(text):\n",
        "    doc = nlp(text)\n",
        "    keywords = [token.text for token in doc if token.is_alpha and not token.is_stop]\n",
        "    return keywords\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA9qQ0VPgmYD",
        "outputId": "8d489e2c-ee15-4011-d089-871da2cb3817"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/google/colab/_pip.py:86: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.11/dist-packages/fuzzywuzzy-0.18.0.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        }
      ],
      "source": [
        "!pip install fuzzywuzzy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ivz4QTEYF4EX",
        "outputId": "9a73f8cc-8b75-49de-8553-5e6d0cf48052"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
            "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n",
            "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|██████████| 79.3M/79.3M [00:00<00:00, 85.7MiB/s]\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The documents provided do not explicitly state whether the lawyer is using the Leiden Guidelines and case law. However, based on the information provided, it can be inferred that the lawyer is likely familiar with these resources. The first document, titled \"Leiden Principles,\" outlines a set of guidelines for lawyers working on human rights cases. It emphasizes the importance of respecting cultural differences and ensuring that legal representation is accessible to all individuals, regardless of their socioeconomic status or geographic location. This aligns closely with the principles outlined in the Leiden Guidelines, which focus on ensuring that legal representation is fair and equitable for all parties involved. Additionally, the second document, which is a court ruling, references the use of case law as a source of legal precedent. This suggests that the lawyer may be familiar with the concept of relying on previous rulings to inform their own arguments and interpretations of the law. While it is not explicitly stated whether the lawyer is using the Leiden Guidelines or case law, the evidence suggests that they are likely familiar with both resources and may be incorporating them into their work.\n",
            "\n",
            " DOCUMENTS: Leiden Guidelines on the Use of Digitally Derived Evidence in International Criminal Courts and Tribunals,\n",
            " - Extrapolations from case law on the use of digitally derived evidence (dde) before international criminal courts and tribunals\n",
            "\n",
            " NOTE: this is only guidance based on past case law.\n"
          ]
        }
      ],
      "source": [
        "# --- Document Excerpts ---\n",
        "# {truncated_context}\n",
        "# Function to enhance the query by adding the extracted keywords\n",
        "from fuzzywuzzy import fuzz\n",
        "\n",
        "titles_list = [doc_metadata['title'] for doc_metadata in metadata_list.values()]\n",
        "\n",
        "def find_full_title(query, titles_list, threshold=60):\n",
        "    matches = [title for title in titles_list if fuzz.partial_ratio(query.lower(), title.lower()) >= threshold]\n",
        "    return matches\n",
        "\n",
        "keywords_list = [doc_metadata['keywords'] for doc_metadata in metadata_list.values()]\n",
        "\n",
        "def find_keywords(search_terms, keywords):\n",
        "    for search_term in search_terms:\n",
        "        if search_term.lower() in keywords:\n",
        "            return search_term.lower()\n",
        "    return None  # No matching title found\n",
        "\n",
        "# TODO - if the chat bot doesn't recognise any keywords it should prompt back and say something like:\n",
        "#  'Ask me about digital evidence related to photographic, video or etc. evidence.'\n",
        "def ask_question_llama(question, leiden_guide_lines, case_law):\n",
        "    # always Leiden Guidelines\n",
        "    metadata_titles = [titles_list[0]]\n",
        "    if case_law:\n",
        "      # Extrapolations from case law\n",
        "      metadata_titles.append(titles_list[1])\n",
        "    # if\n",
        "      # Cases from the ICC, ICTR, ICTY, IRMCT, SCSL and STL\n",
        "    # if\n",
        "      # UN HUMAN RIGHTS FACT-FINDING\n",
        "    # if\n",
        "      # INTERNATIONAL CRIMINAL LAW\n",
        "    extracted_keywords = extract_keywords(question)\n",
        "\n",
        "    metadata_keywords = find_keywords(extracted_keywords, keywords_list)\n",
        "    # metadata_titles = find_full_title(question, titles_list)\n",
        "    \"\"\"Generate an answer to a legal question using LLaMA.\"\"\"\n",
        "    # Get relevant documents\n",
        "    relevant_docs = processor.find_relevant_documents(query=question, metadata_keywords=metadata_keywords, metadata_titles=metadata_titles, n_results=5)\n",
        "\n",
        "    # Prepare context\n",
        "    context_pieces = [doc['text'][4000:5000] for doc in relevant_docs]\n",
        "    titles = [doc['metadata']['title'] for doc in relevant_docs]\n",
        "    keywords = [doc['metadata']['keywords'] for doc in relevant_docs]\n",
        "    truncated_context = \"\\n\".join(context_pieces)\n",
        "    # Create prompt\n",
        "\n",
        "    full_prompt = f\"\"\"You are a Human Rights Lawyer using the documents below to answer the following question.\n",
        "--- Question ---\n",
        "{question}\n",
        "\n",
        "Based on the documents above, provide a clear, concise answer. If relevant, refer to legal precedent, case law, or any specific details from the documents. Do not simply restate the question; make sure the answer is grounded in the provided content.\n",
        "\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "    # Prepare for generation\n",
        "    if torch.cuda.is_available():\n",
        "        model.to('cuda')\n",
        "    # TODO - increase the token limit to allow for more text\n",
        "    inputs = tokenizer(\n",
        "        full_prompt,\n",
        "        return_tensors=\"pt\",\n",
        "        max_length=1024,\n",
        "        truncation=True\n",
        "    )\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = {k: v.to('cuda') for k, v in inputs.items()}\n",
        "    # TODO - increase the token limit to allow for more text\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=800,\n",
        "            temperature=0.7,\n",
        "            do_sample=True\n",
        "        )\n",
        "    # Process output\n",
        "    raw_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    if \"Answer:\" in raw_output:\n",
        "        final_answer = raw_output.split(\"Answer:\", 1)[1].strip()\n",
        "    else:\n",
        "        final_answer = raw_output\n",
        "\n",
        "    docs = \",\\n - \".join(metadata_titles)\n",
        "    final_answer = final_answer + f'\\n\\n DOCUMENTS: {docs}' + '\\n\\n NOTE: this is only guidance based on past case law.'\n",
        "    # print(final_answer )\n",
        "    return final_answer\n",
        "\n",
        "    #\n",
        "\n",
        "answer = ask_question_llama(\"Are you using the Leiden Guidelines and case law ?\", True, True)\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bBSaMH0GCLf"
      },
      "source": [
        "Create User Interface\n",
        "\n",
        "Finally, we can also create the Gradio interface:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "tkXmnZ3qGGIT",
        "outputId": "f0efe8d4-75f0-40ac-b2c3-19931904476b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/http_server.py:120: ResourceWarning: unclosed <socket.socket fd=108, family=2, type=1, proto=0, laddr=('0.0.0.0', 0)>\n",
            "  s = socket.socket()\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://c815b5b4678a3241ef.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://c815b5b4678a3241ef.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def create_interface():\n",
        "    demo = gr.Interface(\n",
        "        fn=ask_question_llama,\n",
        "        inputs=[\n",
        "            gr.Textbox(\n",
        "                label=\"Your Legal Question\",\n",
        "                placeholder=\"Ask any question about your legal documents...\",\n",
        "                lines=3\n",
        "            ),\n",
        "            gr.Checkbox(label=\"Open Source Investigator\", value=True),\n",
        "            gr.Checkbox(label=\"Lawyer\", value=False),\n",
        "            ],\n",
        "        outputs=[\n",
        "            gr.Markdown(\n",
        "                label=\"Answer\",\n",
        "            )\n",
        "        ],\n",
        "\n",
        "        title=\"Legal Document Assistant\",\n",
        "        description=\"This AI assistant can answer questions about your legal documents.\"\n",
        "    )\n",
        "    return demo\n",
        "# Launch interface\n",
        "demo = create_interface()\n",
        "demo.launch(share=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFcYMrFmFiXs"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "Everything below here from the original Medium Article\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft2K0x1bEH87"
      },
      "source": [
        "Option A: Basic Processing (Free, No API Key Needed)\n",
        "\n",
        "If you want to use the basic document processor (good for text-based documents), create a new cell and run this code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lO6oS5sZEGZG"
      },
      "outputs": [],
      "source": [
        "# # Set up basic document processing\n",
        "# processor = DocumentProcessor()\n",
        "# # Add basic document conversion\n",
        "# processor.md = MarkItDown()\n",
        "# logger.info(\"✅ Basic document processor ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6fyQZUjEV7c"
      },
      "source": [
        "Option B: Enhanced Processing (Requires OpenAI API Key)\n",
        "\n",
        "If you want enhanced processing with better image handling and understanding, create a new cell and run this code instead:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRqKsdM2ENmw"
      },
      "outputs": [],
      "source": [
        "# # First, set your OpenAI key\n",
        "# OPENAI_API_KEY = \"your-openai-key-here\"  # Replace with your actual key\n",
        "\n",
        "# # Set up enhanced document processing\n",
        "# from openai import OpenAI\n",
        "# processor = DocumentProcessor()\n",
        "# client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "# processor.md = MarkItDown(llm_client=client, llm_model=\"gpt-4\")\n",
        "# logger.info(\"✅ Enhanced document processor ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIlFcdrCHnyl"
      },
      "source": [
        "Part 3: Choose Your Storage System\n",
        "\n",
        "Next, decide how you want to store your processed documents. You have two options:\n",
        "Option A: Local Storage (Free, Good for Small Projects)\n",
        "\n",
        "If you want to use local storage, create a new cell and run this code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMVQoxjBHwRy"
      },
      "outputs": [],
      "source": [
        "# Set up local storage with Chroma\n",
        "import chromadb\n",
        "processor.vector_db = chromadb.Client()\n",
        "logger.info(\"✅ Local storage ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4-j9Az7H2XX"
      },
      "source": [
        "Option B: Cloud Storage (Requires Qdrant Account)\n",
        "\n",
        "If you want cloud storage, you need to create an account with Qdrant. Follow their instructions. Then, create a new cell and run this code instead:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JB5BRVNH7L1"
      },
      "outputs": [],
      "source": [
        "# First, set your Qdrant credentials\n",
        "QDRANT_URL = \"your-qdrant-url-here\"      # Replace with your URL\n",
        "QDRANT_API_KEY = \"your-qdrant-key-here\"  # Replace with your key\n",
        "# Set up cloud storage with Qdrant\n",
        "from qdrant_client import QdrantClient\n",
        "processor.vector_db = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)\n",
        "logger.info(\"✅ Cloud storage ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNoi8cj_IBUY"
      },
      "source": [
        "Part 4: Connect to Your Documents\n",
        "\n",
        "Now you’ll connect to your documents. Everyone should use Google Drive for this part:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZo1c1A8IHVz",
        "outputId": "575da8fe-2cb5-4306-dc57-8a66177b502c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "# Mount Google Drive\n",
        "logger.info(\"Connecting to Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "# Set up documents folder\n",
        "DOCUMENTS_PATH = '/content/drive/MyDrive/legal_documents'\n",
        "if not os.path.exists(DOCUMENTS_PATH):\n",
        "    os.makedirs(DOCUMENTS_PATH)\n",
        "    logger.info(\"Created 'legal_documents' folder in your Google Drive\")\n",
        "    logger.info(\"⚠️ Please add your documents to this folder before continuing\")\n",
        "else:\n",
        "    logger.info(\"✅ Found 'legal_documents' folder\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeeYWEHEHLYJ"
      },
      "source": [
        "Part 5: Choose Your AI Model\n",
        "\n",
        "Finally, decide which AI model you want to use for answering questions. You have two options:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA_9wQFFG6ZT"
      },
      "source": [
        "Open AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-9GR0AbG-eL"
      },
      "outputs": [],
      "source": [
        "# First, ensure you have your OpenAI key\n",
        "OPENAI_API_KEY = \"your-openai-key-here\"  # Replace with your actual key\n",
        "# Set up GPT-4\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "model = ChatOpenAI(\n",
        "    model=\"gpt-4\",\n",
        "    openai_api_key=OPENAI_API_KEY,\n",
        "    temperature=0.7\n",
        ")\n",
        "logger.info(\"✅ GPT-4 model ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhggK9BzF7ZP"
      },
      "source": [
        "Llama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87iMolWOF8w7"
      },
      "outputs": [],
      "source": [
        "# First, set your HuggingFace token\n",
        "HF_TOKEN = \"your-huggingface-token-here\"  # Replace with your actual token\n",
        "# Set up Llama\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"meta-llama/Llama-3.1-8B\",\n",
        "    token=HF_TOKEN\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"meta-llama/Llama-3.1-8B\",\n",
        "    token=HF_TOKEN\n",
        ")\n",
        "logger.info(\"✅ Llama model ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNHgD5RjIioe"
      },
      "source": [
        "Part 6: Process Your Documents\n",
        "\n",
        "Now that everything is set up, create a new cell to process your documents:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xA29aqVPIjQJ"
      },
      "outputs": [],
      "source": [
        "# Get list of documents\n",
        "document_files = [f for f in os.listdir(DOCUMENTS_PATH)\n",
        "                 if f.endswith(('.pdf', '.docx', '.txt', '.html', '.pptx'))]\n",
        "\n",
        "if not document_files:\n",
        "    logger.info(\"⚠️ No documents found! Add some to your legal_documents folder\")\n",
        "else:\n",
        "    logger.info(f\"Found {len(document_files)} documents to process\")\n",
        "    # Process each document\n",
        "    for document in document_files:\n",
        "        try:\n",
        "            logger.info(f\"Processing {document}...\")\n",
        "            file_path = os.path.join(DOCUMENTS_PATH, document)\n",
        "            result = processor.process_document(file_path)\n",
        "            logger.info(f\"✅ Processed {document}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error processing {document}: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72YXoZ9cIvaX"
      },
      "source": [
        "Part 7: Final Testing\n",
        "\n",
        "Create one last cell to test your assistant. The code depends on which AI model you chose:\n",
        "If You Chose GPT-4:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_NeWbxmIv6y"
      },
      "outputs": [],
      "source": [
        "def ask_question(question):\n",
        "    prompt = f\"Based on the legal documents, please answer: {question}\"\n",
        "    return model.predict(prompt)\n",
        "\n",
        "# Test the system\n",
        "test_question = \"What are the main terms of the agreement?\"\n",
        "answer = ask_question(test_question)\n",
        "print(f\"Question: {test_question}\")\n",
        "print(f\"Answer: {answer}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-d5pFccI-Jr"
      },
      "source": [
        "If You Chose Llama:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioXpuGaVI-mb"
      },
      "outputs": [],
      "source": [
        "def ask_question(question):\n",
        "    prompt = f\"Question about legal documents: {question}\\nAnswer:\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    outputs = model.generate(**inputs, max_new_tokens=200, temperature=0.7)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Test the system\n",
        "test_question = \"What are the main terms of the agreement?\"\n",
        "answer = ask_question(test_question)\n",
        "print(f\"Question: {test_question}\")\n",
        "print(f\"Answer: {answer}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmIye0rVJJIM"
      },
      "source": [
        "Part 8: Creating Your User Interface\n",
        "\n",
        "Now that we have our assistant working, let’s create a user-friendly interface. This will make it easy for anyone to ask questions about your legal documents. We’ll use Gradio, a tool that helps create web interfaces for AI applications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N2rWAa5XJJln",
        "outputId": "c80392bb-d2a5-44c5-9b01-a9a91c6ad821"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.12.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.115.6)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.5.4 (from gradio)\n",
            "  Downloading gradio_client-1.5.4-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.5)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.4)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.9.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.41.3)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.4->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.4->gradio) (14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.12.0-py3-none-any.whl (57.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.5.4-py3-none-any.whl (321 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.4/321.4 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.9.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Installing collected packages: tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, safehttpx, gradio-client, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 ffmpy-0.5.0 gradio-5.12.0 gradio-client-1.5.4 markupsafe-2.1.5 python-multipart-0.0.20 ruff-0.9.1 safehttpx-0.1.6 semantic-version-2.10.0 tomlkit-0.13.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:86: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/MarkupSafe-2.1.5.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:86: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/semantic_version-2.10.0.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "986396d9685c4f939bdb45466df4ba78",
              "pip_warning": {
                "packages": [
                  "markupsafe"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Gradio installation complete!\n"
          ]
        }
      ],
      "source": [
        "# Install Gradio for our interface\n",
        "!pip install gradio\n",
        "print(\"✅ Gradio installation complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vynfB7t5J20u"
      },
      "source": [
        "Step 2: Choose Your Interface Setup\n",
        "\n",
        "Now you’ll need to set up the interface based on which AI model you chose earlier. Pick the option that matches your previous choice:\n",
        "Option A: Interface with GPT-4\n",
        "\n",
        "If you’re using GPT-4, create a new cell and run this code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "BZkCszVqJNOe",
        "outputId": "1914213c-73d6-4bb8-d118-63bc4193f4a1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/websockets/legacy/__init__.py:6: DeprecationWarning: websockets.legacy is deprecated; see https://websockets.readthedocs.io/en/stable/howto/upgrade.html for upgrade instructions\n",
            "  warnings.warn(  # deprecated in 14.0 - 2024-11-09\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-7b310c25edac>\u001b[0m in \u001b[0;36m<cell line: 46>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdemo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# Create and launch the interface\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mdemo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_gpt4_interface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mdemo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshare\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# share=True creates a public link you can share\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✅ Interface is ready! Click the link above to start using your assistant.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "from typing import List, Dict\n",
        "import logging\n",
        "def create_gpt4_interface(model, processor):\n",
        "    \"\"\"Creates an interface for GPT-4 based assistant\"\"\"\n",
        "    def get_response(question: str) -> str:\n",
        "        \"\"\"Process a question and get GPT-4's response\"\"\"\n",
        "        try:\n",
        "            # Find relevant document sections\n",
        "            relevant_docs = processor.find_relevant_documents(question)\n",
        "            context = \"\\n\\n\".join(doc.text for doc in relevant_docs)\n",
        "            # Create our prompt\n",
        "            prompt = f\"\"\"As a legal expert, please answer this question based on\n",
        "            the provided documents:\n",
        "            Documents: {context}\n",
        "            Question: {question}\n",
        "            \"\"\"\n",
        "            # Get GPT-4's response\n",
        "            response = model.predict(prompt)\n",
        "            return response\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error processing question: {str(e)}\")\n",
        "            return f\"I encountered an error: {str(e)}\"\n",
        "    # Create the interface\n",
        "    demo = gr.Interface(\n",
        "        fn=get_response,\n",
        "        inputs=[\n",
        "            gr.Textbox(\n",
        "                label=\"Your Legal Question\",\n",
        "                placeholder=\"Ask any question about your legal documents...\",\n",
        "                lines=3\n",
        "            )\n",
        "        ],\n",
        "        outputs=[\n",
        "            gr.Textbox(\n",
        "                label=\"Answer\",\n",
        "                lines=10\n",
        "            )\n",
        "        ],\n",
        "        title=\"Legal Document Assistant (GPT-4)\",\n",
        "        description=\"\"\"This AI assistant can answer questions about your legal documents.\n",
        "        It uses GPT-4 to provide accurate, contextual responses based on your documents.\"\"\"\n",
        "    )\n",
        "    return demo\n",
        "# Create and launch the interface\n",
        "demo = create_gpt4_interface(model, processor)\n",
        "demo.launch(share=True)  # share=True creates a public link you can share\n",
        "print(\"✅ Interface is ready! Click the link above to start using your assistant.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtxKnHklKM8j"
      },
      "source": [
        "Option B: Interface with Llama\n",
        "\n",
        "If you’re using Llama, create a new cell and run this code instead:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tx9Y8zVvJ-sD"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "from typing import List, Dict\n",
        "import logging\n",
        "\n",
        "def create_llama_interface(model, tokenizer, processor):\n",
        "    \"\"\"Creates an interface for Llama-based assistant\"\"\"\n",
        "    def get_response(question: str) -> str:\n",
        "        \"\"\"Process a question and get Llama's response\"\"\"\n",
        "        try:\n",
        "            # Find relevant document sections\n",
        "            relevant_docs = processor.find_relevant_documents(question)\n",
        "            context = \"\\n\\n\".join(doc.text for doc in relevant_docs)\n",
        "            # Create our prompt\n",
        "            prompt = f\"\"\"Please answer this legal question based on the provided\n",
        "            documents. Be specific and cite relevant sections.\n",
        "            Documents: {context}\n",
        "            Question: {question}\n",
        "            Answer:\"\"\"\n",
        "            # Prepare for Llama\n",
        "            inputs = tokenizer(\n",
        "                prompt,\n",
        "                return_tensors=\"pt\",\n",
        "                max_length=2048,\n",
        "                truncation=True\n",
        "            )\n",
        "            # Generate response\n",
        "            outputs = model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=512,\n",
        "                temperature=0.7,\n",
        "                do_sample=True\n",
        "            )\n",
        "            # Decode response\n",
        "            response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            return response.split(\"Answer:\")[-1].strip()\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error processing question: {str(e)}\")\n",
        "            return f\"I encountered an error: {str(e)}\"\n",
        "    # Create the interface\n",
        "    demo = gr.Interface(\n",
        "        fn=get_response,\n",
        "        inputs=[\n",
        "            gr.Textbox(\n",
        "                label=\"Your Legal Question\",\n",
        "                placeholder=\"Ask any question about your legal documents...\",\n",
        "                lines=3\n",
        "            )\n",
        "        ],\n",
        "        outputs=[\n",
        "            gr.Textbox(\n",
        "                label=\"Answer\",\n",
        "                lines=10\n",
        "            )\n",
        "        ],\n",
        "        title=\"Legal Document Assistant (Llama)\",\n",
        "        description=\"\"\"This AI assistant can answer questions about your legal documents.\n",
        "        It uses Llama to provide detailed responses based on your documents.\"\"\"\n",
        "    )\n",
        "    return demo\n",
        "# Create and launch the interface\n",
        "demo = create_llama_interface(model, tokenizer, processor)\n",
        "demo.launch(share=True)  # share=True creates a public link you can share\n",
        "print(\"✅ Interface is ready! Click the link above to start using your assistant.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIFTYQD0KWoU"
      },
      "source": [
        "Step 3: Enhanced Interface (Optional)\n",
        "\n",
        "If you want a more sophisticated interface with additional features, create a new cell and run this code (works with either model):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "GDuc11vtKXFI",
        "outputId": "d92bbe03-a997-44bb-cf0d-883599285ca7"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-10-7b47c5f5b820>, line 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-7b47c5f5b820>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    mport gradio as gr\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "from typing import List, Dict\n",
        "import logging\n",
        "\n",
        "def create_advanced_interface(model, processor, model_type=\"gpt-4\"):\n",
        "    \"\"\"Creates an enhanced interface with additional features\"\"\"\n",
        "    def process_query(\n",
        "        question: str,\n",
        "        show_sources: bool,\n",
        "        response_length: str\n",
        "    ) -> Dict[str, str]:\n",
        "        \"\"\"Process a question with additional options\"\"\"\n",
        "        try:\n",
        "            # Find relevant documents\n",
        "            relevant_docs = processor.find_relevant_documents(question)\n",
        "            context = \"\\n\\n\".join(doc.text for doc in relevant_docs)\n",
        "            # Adjust response length\n",
        "            max_tokens = {\n",
        "                \"Brief\": 100,\n",
        "                \"Detailed\": 300,\n",
        "                \"Comprehensive\": 500\n",
        "            }[response_length]\n",
        "            # Get response based on model type\n",
        "            if model_type == \"gpt-4\":\n",
        "                response = model.predict(\n",
        "                    f\"Please provide a {response_length.lower()} answer: \" + context\n",
        "                )\n",
        "            else:  # Llama\n",
        "                inputs = tokenizer(context, return_tensors=\"pt\", truncation=True)\n",
        "                outputs = model.generate(\n",
        "                    **inputs,\n",
        "                    max_new_tokens=max_tokens,\n",
        "                    temperature=0.7\n",
        "                )\n",
        "                response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            # Prepare return value\n",
        "            result = {\"answer\": response}\n",
        "            # Add sources if requested\n",
        "            if show_sources:\n",
        "                sources = \"\\n\\n\".join(\n",
        "                    f\"From {doc.source}:\\n{doc.text[:200]}...\"\n",
        "                    for doc in relevant_docs\n",
        "                )\n",
        "                result[\"sources\"] = sources\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error: {str(e)}\")\n",
        "            return {\"answer\": f\"Error: {str(e)}\", \"sources\": \"\"}\n",
        "    # Create enhanced interface\n",
        "    demo = gr.Interface(\n",
        "        fn=process_query,\n",
        "        inputs=[\n",
        "            gr.Textbox(\n",
        "                label=\"Your Legal Question\",\n",
        "                placeholder=\"Ask any question about your legal documents...\",\n",
        "                lines=3\n",
        "            ),\n",
        "            gr.Checkbox(label=\"Show Source Documents\"),\n",
        "            gr.Radio(\n",
        "                choices=[\"Brief\", \"Detailed\", \"Comprehensive\"],\n",
        "                label=\"Response Length\",\n",
        "                value=\"Detailed\"\n",
        "            )\n",
        "        ],\n",
        "        outputs=[\n",
        "            gr.Textbox(label=\"Answer\", lines=10),\n",
        "            gr.Textbox(label=\"Source Documents\", visible=False) # Shows when sources requested\n",
        "        ],\n",
        "        title=f\"Advanced Legal Assistant ({model_type})\",\n",
        "        description=\"\"\"This enhanced AI assistant can answer questions about your legal documents.\n",
        "        You can customize the response length and choose to see source documents.\"\"\"\n",
        "    )\n",
        "    return demo\n",
        "# Create and launch the enhanced interface\n",
        "demo = create_advanced_interface(model, processor, model_type=\"gpt-4\")  # or \"llama\"\n",
        "demo.launch(share=True)\n",
        "print(\"✅ Enhanced interface is ready! Click the link above to start using your assistant.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_AVuU1zKu3o"
      },
      "source": [
        "Interface Features Explained\n",
        "\n",
        "The interfaces we’ve created offer different features:\n",
        "\n",
        "    Basic Interface (Options A and B):\n",
        "\n",
        "    Simple question input\n",
        "    Clear answer output\n",
        "    Model-specific optimizations\n",
        "    Automatic error handling\n",
        "\n",
        "2. Enhanced Interface (Optional):\n",
        "\n",
        "    Adjustable response length\n",
        "    Option to show source documents\n",
        "    More sophisticated error handling\n",
        "    Better context management\n",
        "\n",
        "When using your interface:\n",
        "\n",
        "    The URL provided will work as long as your Colab notebook is running\n",
        "    You can share the link with others (if you used share=True)\n",
        "    The interface will work with your processed documents\n",
        "    Responses might take a few seconds, especially with longer questions\n",
        "\n",
        "Troubleshooting Interface Issues\n",
        "\n",
        "If you encounter problems:\n",
        "\n",
        "    Interface Won’t Load:\n",
        "\n",
        "    Make sure all previous cells ran successfully\n",
        "    Check that Gradio installed correctly\n",
        "    Verify your model connection is working\n",
        "\n",
        "2. Slow Responses:\n",
        "\n",
        "    Try shorter questions first\n",
        "    Reduce the context window size\n",
        "    Use the “Brief” response length option\n",
        "\n",
        "3. Error Messages:\n",
        "\n",
        "    Check your API keys are still valid\n",
        "    Verify your documents were processed correctly\n",
        "    Look for error messages in the Colab output\n",
        "\n",
        "Remember:\n",
        "\n",
        "    Keep your Colab notebook running while using the interface\n",
        "    The public URL changes each time you run the cell\n",
        "    Save your interface URL if you want to share it\n",
        "    Monitor your API usage if using GPT-4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AX0yx8HK65R"
      },
      "source": [
        "Optional Advanced Step: Teaching Your Assistant\n",
        "\n",
        "If you’ve been using your legal assistant and want to make it even better at handling your specific legal questions, you can teach it using your own examples. This process has two main parts:\n",
        "\n",
        "    Creating training examples (easier)\n",
        "    Fine-tuning and deploying the model (more advanced)\n",
        "\n",
        "You can do just the first part to prepare your training data, and come back to the second part when you’re ready for the more technical steps.\n",
        "Part 1: Creating Your Training Examples\n",
        "\n",
        "First, let’s create some examples that will help your assistant learn. We’ll use a friendly tool that makes this process easier. Create a new notebook called “Legal_Assistant_Training” and add this cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrJ7HnDjKhjg"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from IPython.display import display, clear_output\n",
        "import ipywidgets as widgets\n",
        "\n",
        "class ExampleCreator:\n",
        "    \"\"\"A friendly tool to help create training examples\"\"\"\n",
        "    def __init__(self):\n",
        "        self.examples = []\n",
        "        self.filename = 'training_data.jsonl'\n",
        "        # Create our input boxes\n",
        "        self.question_box = widgets.Textarea(\n",
        "            description='Question:',\n",
        "            placeholder='Type your legal question here...',\n",
        "            layout={'width': '90%', 'height': '100px'}\n",
        "        )\n",
        "        self.answer_box = widgets.Textarea(\n",
        "            description='Answer:',\n",
        "            placeholder='Type the correct answer here...',\n",
        "            layout={'width': '90%', 'height': '200px'}\n",
        "        )\n",
        "        # Create our buttons\n",
        "        self.save_button = widgets.Button(description='Save Example')\n",
        "        self.save_button.on_click(self.save_example)\n",
        "        self.display_button = widgets.Button(description='Show All Examples')\n",
        "        self.display_button.on_click(self.show_examples)\n",
        "        # Show our tool\n",
        "        display(self.question_box)\n",
        "        display(self.answer_box)\n",
        "        display(self.save_button)\n",
        "        display(self.display_button)\n",
        "    def save_example(self, button):\n",
        "        \"\"\"Save a new example\"\"\"\n",
        "        question = self.question_box.value.strip()\n",
        "        answer = self.answer_box.value.strip()\n",
        "        if not question or not answer:\n",
        "            print(\"❌ Please provide both a question and an answer!\")\n",
        "            return\n",
        "        # Create the example\n",
        "        example = {\n",
        "            \"conversations\": [\n",
        "                {\"from\": \"human\", \"value\": question},\n",
        "                {\"from\": \"gpt\", \"value\": answer}\n",
        "            ]\n",
        "        }\n",
        "        # Save it\n",
        "        with open(self.filename, 'a') as f:\n",
        "            f.write(json.dumps(example) + '\\n')\n",
        "        self.examples.append(example)\n",
        "        # Clear the boxes for next example\n",
        "        self.question_box.value = ''\n",
        "        self.answer_box.value = ''\n",
        "        print(f\"✅ Example saved! You now have {len(self.examples)} examples.\")\n",
        "    def show_examples(self, button):\n",
        "        \"\"\"Show all saved examples\"\"\"\n",
        "        clear_output(wait=True)\n",
        "        print(f\"Your {len(self.examples)} Training Examples:\\n\")\n",
        "        for i, example in enumerate(self.examples, 1):\n",
        "            print(f\"Example {i}:\")\n",
        "            print(f\"Q: {example['conversations'][0]['value']}\")\n",
        "            print(f\"A: {example['conversations'][1]['value']}\\n\")\n",
        "        # Show our tool again\n",
        "        display(self.question_box)\n",
        "        display(self.answer_box)\n",
        "        display(self.save_button)\n",
        "        display(self.display_button)\n",
        "# Create our example creator tool\n",
        "creator = ExampleCreator()\n",
        "print(\"✨ Example Creator is ready! Start adding your training examples above.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wh39FNJyLO_Y"
      },
      "source": [
        "Let’s add some starter examples to help you understand the format. Add this cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ue_vaT7zLPeL"
      },
      "outputs": [],
      "source": [
        "# Some example legal questions and answers to get you started\n",
        "starter_examples = [\n",
        "    {\n",
        "        \"question\": \"What makes a contract valid?\",\n",
        "        \"answer\": \"A valid contract requires four essential elements: 1) Offer and acceptance, \"\n",
        "                 \"2) Consideration (something of value exchanged), 3) Intention to create \"\n",
        "                 \"legal relations, and 4) Capacity of the parties to contract. The agreement \"\n",
        "                 \"must also be legal and sufficiently certain in its terms.\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"How does force majeure work in contracts?\",\n",
        "        \"answer\": \"Force majeure clauses excuse a party from performing their contractual \"\n",
        "                 \"obligations when extraordinary events beyond their control prevent \"\n",
        "                 \"performance. These events typically include natural disasters, wars, or \"\n",
        "                 \"government actions. The clause must specifically define what constitutes \"\n",
        "                 \"force majeure, and the party claiming it must prove the event's impact.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Add these examples using our tool\n",
        "for example in starter_examples:\n",
        "    with open('training_data.jsonl', 'a') as f:\n",
        "        formatted_example = {\n",
        "            \"conversations\": [\n",
        "                {\"from\": \"human\", \"value\": example[\"question\"]},\n",
        "                {\"from\": \"gpt\", \"value\": example[\"answer\"]}\n",
        "            ]\n",
        "        }\n",
        "        f.write(json.dumps(formatted_example) + '\\n')\n",
        "print(\"✅ Added starter examples to your training data!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeM2RVMWLbq5"
      },
      "source": [
        "Now you can use the tool to add your own examples. Here are some tips for creating good examples:\n",
        "\n",
        "    Include different types of questions:\n",
        "\n",
        "    What is… (definitions)\n",
        "    How does… (processes)\n",
        "    Why is… (reasoning)\n",
        "    When should… (timing)\n",
        "\n",
        "2. Make sure your answers:\n",
        "\n",
        "    Start with a clear main point\n",
        "    Include specific details\n",
        "    Use proper legal terminology\n",
        "    Stay concise but complete\n",
        "\n",
        "Try to create at least 20–30 examples before moving on to the next part.\n",
        "## Part 2: Fine-Tuning and Deploying Your Model\n",
        "\n",
        "Once you have your training examples ready, you can use them to improve your model. This part is more technical and requires a new Colab notebook with more computational resources.\n",
        "\n",
        "Create a new notebook called “Legal_Assistant_Finetuning” and add these cells:\n",
        "Cell 1: Install Training Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mEyr9o5bLdnm",
        "outputId": "2f0bc354-6c6d-4a3f-b61d-207ed7645601"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-4tr4nd6i/unsloth_e4b5dcea890c4a99aa516d0b5d61c0ac\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-4tr4nd6i/unsloth_e4b5dcea890c4a99aa516d0b5d61c0ac\n",
            "  Resolved https://github.com/unslothai/unsloth.git to commit 5dddf27f3ba94506c48251e907031039eecd40d1\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting unsloth_zoo>=2025.1.2 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading unsloth_zoo-2025.1.3-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.2)\n",
            "Collecting tyro (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading tyro-0.9.8-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: transformers!=4.47.0,>=4.46.1 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.49.0.dev0)\n",
            "Collecting datasets>=2.16.0 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.45.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.26.4)\n",
            "Collecting protobuf<4.0.0 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.27.1)\n",
            "Collecting hf_transfer (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting bitsandbytes>=0.43.3 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.5.1+cu121)\n",
            "Requirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\n",
            "Collecting xxhash (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.11.11)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.5.1)\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2025.1.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.0)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2025.1.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.2.1)\n",
            "Collecting trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 (from unsloth_zoo>=2025.1.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading trl-0.13.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2025.1.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.14.0)\n",
            "Collecting cut_cross_entropy (from unsloth_zoo>=2025.1.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2025.1.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.1.0)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.9.4)\n",
            "Collecting shtab>=1.5.6 (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.4.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.12.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.5)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.1.5)\n",
            "Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unsloth_zoo-2025.1.3-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.9.8-py3-none-any.whl (113 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.8/113.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
            "Downloading trl-0.13.0-py3-none-any.whl (293 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.4/293.4 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
            "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: unsloth\n",
            "  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unsloth: filename=unsloth-2025.1.5-py3-none-any.whl size=176838 sha256=8a9a4a0b877094cd1e0bff6902d61a5dc22d8c915c89713453c8ad6d76b28758\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5ajf0c9m/wheels/ed/d4/e9/76fb290ee3df0a5fc21ce5c2c788e29e9607a2353d8342fd0d\n",
            "Successfully built unsloth\n",
            "Installing collected packages: xxhash, unsloth, shtab, protobuf, hf_transfer, fsspec, dill, multiprocess, tyro, cut_cross_entropy, bitsandbytes, datasets, trl, unsloth_zoo\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.3\n",
            "    Uninstalling protobuf-5.29.3:\n",
            "      Successfully uninstalled protobuf-5.29.3\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\n",
            "opentelemetry-proto 1.29.0 requires protobuf<6.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bitsandbytes-0.45.0 cut_cross_entropy-25.1.1 datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 hf_transfer-0.1.9 multiprocess-0.70.16 protobuf-3.20.3 shtab-1.7.1 trl-0.13.0 tyro-0.9.8 unsloth-2025.1.5 unsloth_zoo-2025.1.3 xxhash-3.5.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:86: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/bitsandbytes-0.45.0.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:86: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/cut_cross_entropy-25.1.1.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:86: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/datasets-3.2.0.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:86: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/dill-0.3.8.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:86: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/multiprocess-0.70.16.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:86: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/protobuf-3.20.3.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:86: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/shtab-1.7.1.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:86: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/trl-0.13.0.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:86: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/unsloth-2025.1.5.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:86: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/unsloth_zoo-2025.1.3.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:86: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/xxhash-3.5.0.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "7456b422629946e8b44407f92247c422",
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting xformers<0.0.27\n",
            "  Downloading xformers-0.0.26.post1-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting trl<0.9.0\n",
            "  Downloading trl-0.8.6-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.14.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.45.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
            "Downloading xformers-0.0.26.post1-cp310-cp310-manylinux2014_x86_64.whl (222.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.7/222.7 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.8.6-py3-none-any.whl (245 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.2/245.2 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xformers, trl\n",
            "  Attempting uninstall: trl\n",
            "    Found existing installation: trl 0.13.0\n",
            "    Uninstalling trl-0.13.0:\n",
            "      Successfully uninstalled trl-0.13.0\n",
            "Successfully installed trl-0.8.6 xformers-0.0.26.post1\n",
            "✅ Training packages installed\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:86: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/trl-0.8.6.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:86: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/xformers-0.0.26.post1.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        }
      ],
      "source": [
        "# Install specialized training packages\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps \"xformers<0.0.27\" \"trl<0.9.0\" peft accelerate bitsandbytes datasets\n",
        "\n",
        "print(\"✅ Training packages installed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2V4uujULtwQ"
      },
      "source": [
        "Cell 2: Initialize Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3u_9sL3_LoJl"
      },
      "outputs": [],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "from transformers import TrainingArguments\n",
        "from trl import SFTTrainer\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "\n",
        "# Set up model for training\n",
        "max_seq_length = 2048\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    load_in_4bit=True,\n",
        "    dtype=None\n",
        ")\n",
        "# Prepare for fine-tuning\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=16,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
        "    use_gradient_checkpointing=True\n",
        ")\n",
        "print(\"✅ Model prepared for training\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzM9LxMGL5f6"
      },
      "source": [
        "Cell 3: Upload and Train\n",
        "\n",
        "First, upload your training_data.jsonl file that you created in the previous part of this guide, then run:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyL9DawkL6Bq"
      },
      "outputs": [],
      "source": [
        "# Load your training data\n",
        "dataset = load_dataset('json', data_files='training_data.jsonl')\n",
        "\n",
        "# Configure training\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./legal_assistant_model\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=2e-4,\n",
        "    logging_steps=10,\n",
        "    save_strategy=\"epoch\"\n",
        ")\n",
        "# Create trainer\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset['train'],\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_args,\n",
        "    packing=False\n",
        ")\n",
        "# Start training\n",
        "print(\"Starting training...\")\n",
        "trainer.train()\n",
        "print(\"✅ Training complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Q3nz9A8MEw8"
      },
      "source": [
        "Cell 4: Save and Share Your Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBnV5cPcMFiL"
      },
      "outputs": [],
      "source": [
        "# First, log in to Hugging Face\n",
        "from huggingface_hub import login\n",
        "login()  # You'll need to enter your Hugging Face token\n",
        "\n",
        "# Save locally\n",
        "trainer.save_model(\"./FineTunedLegal\")\n",
        "# Push to Hugging Face Hub\n",
        "model_name = \"your-username/LegalAssistant\"  # Change this to your desired name\n",
        "model.push_to_hub(model_name, tokenizer)\n",
        "print(f\"✅ Model saved and pushed to {model_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y5hH2m7MOy2"
      },
      "source": [
        "Using Your Improved Model\n",
        "\n",
        "To use your newly trained model, go back to your original legal assistant notebook and update the model loading cell with:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkoM4g3EMPOE"
      },
      "outputs": [],
      "source": [
        "# Replace the original model loading code with:\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"your-username/LegalAssistant\",  # Use your model's name\n",
        "    token=\"your-huggingface-token\"\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"your-username/LegalAssistant\",\n",
        "    token=\"your-huggingface-token\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFcIRLLuMZDd"
      },
      "source": [
        "Your assistant will now use your improved model that’s been trained on your specific examples. It should be better at handling the types of questions you included in your training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OuQKr0yjMaJ_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}